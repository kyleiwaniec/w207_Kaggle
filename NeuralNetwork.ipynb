{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# San Francisco Crime prediction \n",
    "# Based on 2 layer neural net and count featurizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import re\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from matplotlib.colors import LogNorm\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from copy import deepcopy\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainDF=pd.read_csv(\"data/train.csv\")\n",
    "trainDF = trainDF.sample(150000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up wrong X and Y values (very few of them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEACAYAAABRQBpkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5634bf0050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xy_scaler=preprocessing.StandardScaler()\n",
    "xy_scaler.fit(trainDF[[\"X\",\"Y\"]])\n",
    "trainDF[[\"X\",\"Y\"]]=xy_scaler.transform(trainDF[[\"X\",\"Y\"]])\n",
    "trainDF=trainDF[abs(trainDF[\"Y\"])<100]\n",
    "trainDF.index=range(len(trainDF))\n",
    "plt.plot(trainDF[\"X\"],trainDF[\"Y\"],'.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split train data into train and dev 80:20, and separate into X,Y\n",
    "# train_data = df\n",
    "# shuffle the data:\n",
    "trainDF = trainDF.reindex(np.random.permutation(trainDF.index))\n",
    "\n",
    "# take 80% from the top:\n",
    "upper = np.floor(len(trainDF)*.8).astype(int)\n",
    "train_data = trainDF.head(n=upper)\n",
    "train_labels = train_data['Category']\n",
    "\n",
    "# take 20% from the bottom\n",
    "lower = np.ceil(len(trainDF)*.2).astype(int)\n",
    "dev_data = trainDF.tail(n=lower)\n",
    "dev_labels = dev_data['Category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make plots for each crime label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now proceed as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_time(x):\n",
    "    DD=datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\")\n",
    "    time=DD.hour#*60+DD.minute\n",
    "    day=DD.day\n",
    "    month=DD.month\n",
    "    year=DD.year\n",
    "    return time,day,month,year\n",
    "\n",
    "def get_season(x):\n",
    "    summer=0\n",
    "    fall=0\n",
    "    winter=0\n",
    "    spring=0\n",
    "    if (x in [5, 6, 7]):\n",
    "        summer=1\n",
    "    if (x in [8, 9, 10]):\n",
    "        fall=1\n",
    "    if (x in [11, 0, 1]):\n",
    "        winter=1\n",
    "    if (x in [2, 3, 4]):\n",
    "        spring=1\n",
    "    return summer, fall, winter, spring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ScalerTransform(TransformerMixin):\n",
    "    \n",
    "    def __init__(self,cols=[],include=True):\n",
    "        self.cols = cols\n",
    "        self.include = include\n",
    "\n",
    "    def transform(self, X,y=None, **transform_params):\n",
    "        print(\"Scaler\")\n",
    "        if self.include:\n",
    "            x_num_train = X[self.cols]\n",
    "        else:\n",
    "            x_num_train = X.drop( self.cols, axis = 1 )\n",
    "        return self.scaler.transform(x_num_train)\n",
    "      \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        if self.include:\n",
    "            x_num_train = X[self.cols]\n",
    "        else:\n",
    "            x_num_train = X.drop( self.cols, axis = 1 )      \n",
    "        self.scaler = preprocessing.StandardScaler().fit(x_num_train)\n",
    "        return self\n",
    "\n",
    "\n",
    "class DatesTransformer(TransformerMixin):\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        if('Dates' in X):\n",
    "            print(\"Dates\")\n",
    "\n",
    "            DD =X['Dates'].apply(lambda x: datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\"))\n",
    "            time,day,month,year  =  DD.dt.hour, DD.dt.day,DD.dt.month,DD.dt.year  \n",
    "            return np.array([time,day,month,year]).T\n",
    "        return \n",
    "        \n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "class SeasonsTransformer(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        print(\"Seasons\")\n",
    "\n",
    "        def get_season(x):\n",
    "            summer=0\n",
    "            fall=0\n",
    "            winter=0\n",
    "            spring=0\n",
    "            if (x in [5, 6, 7]):\n",
    "                summer=1\n",
    "            if (x in [8, 9, 10]):\n",
    "                fall=1\n",
    "            if (x in [11, 0, 1]):\n",
    "                winter=1\n",
    "            if (x in [2, 3, 4]):\n",
    "                spring=1\n",
    "            return summer, fall, winter, spring\n",
    "        \n",
    "        if('Dates' in X):\n",
    "            DD =X['Dates'].apply(lambda x: datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\"))\n",
    "            awake=DD.dt.hour.apply(lambda x: 1 if (x==0 or (x>=8 and x<=23)) else 0)\n",
    "            summer, fall, winter, spring=zip(*DD.dt.month.apply(get_season))\n",
    "            return  np.array([awake,summer,fall,winter,spring]).T        \n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "class AddIsIntersectionTransformer(TransformerMixin):\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        print(\"Intersection\")\n",
    "\n",
    "        if('Address' in X):\n",
    "            return (X[\"Address\"].apply(lambda x: 1 if \"/\" in x else 0))[:,None]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self    \n",
    "    \n",
    "class StreetNamesTransformer(TransformerMixin):\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        def getstreet(x):\n",
    "            if  \"/\" in x: \n",
    "                return re.findall(r'([A-Z0-9 ]+)\\s/\\s([A-Z0-9 ]+)', x)\n",
    "            else: \n",
    "                street = re.findall(r'\\d+.*?\\s+Block of ([A-Z0-9 ]+)', x)\n",
    "                return [street, street]\n",
    "        \n",
    "        print(\"StreetNames\")\n",
    "        X2 = X.copy()\n",
    "        streets = X[\"Address\"].apply(getstreet)\n",
    "        X2['street1'] = streets[0]\n",
    "        X2['street2'] = streets[1]\n",
    "\n",
    "        return X2\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self    \n",
    "    \n",
    "class LogOddsTransformer(TransformerMixin):\n",
    "    def __init__(self,togroup):\n",
    "        self.togroup = togroup\n",
    "\n",
    "        \n",
    "    def transform(self, X, **transform_params):\n",
    "        print \"LogOdds transform\"\n",
    "        col = X[','.join(self.togroup)] \n",
    "        address_features=col.apply(lambda x: self.logodds[x])\n",
    "        PA = col.apply(lambda x: self.logoddsPA[x])\n",
    "        return np.hstack((address_features,PA[:,np.newaxis]))\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        print(\"LogOdds\")\n",
    "        categories=sorted(X[\"Category\"].unique())\n",
    "        X2 = X.assign(Category=y.astype('object'))\n",
    "        C_counts=X2.groupby([\"Category\"]).size()\n",
    "        A_C_counts=X2.groupby(self.togroup +[\"Category\"]).size()\n",
    "        A_counts=X2.groupby(self.togroup).size()\n",
    "        addresses=A_counts.keys()\n",
    "        logodds={}\n",
    "        logoddsPA={}\n",
    "        MIN_CAT_COUNTS=2\n",
    "        default_logodds=np.log(C_counts/len(X2))-np.log(1.0-C_counts/float(len(X2)))\n",
    "        for addr in addresses:\n",
    "            PA=A_counts[addr]/float(len(X2))\n",
    "            logoddsPA[addr]=np.log(PA)-np.log(1.-PA)\n",
    "            logodds[addr]=deepcopy(default_logodds)\n",
    "            for cat in A_C_counts[addr].keys():\n",
    "                if (A_C_counts[addr][cat]>MIN_CAT_COUNTS) and A_C_counts[addr][cat]<A_counts[addr]:\n",
    "                    PA=A_C_counts[addr][cat]/float(A_counts[addr])\n",
    "                    logodds[addr][categories.index(cat)]=np.log(PA)-np.log(1.0-PA)\n",
    "            logodds[addr]=pd.Series(logodds[addr])\n",
    "            logodds[addr].index=range(len(categories))\n",
    "        self.logodds=logodds\n",
    "        self.logoddsPA=logoddsPA\n",
    "        return self       \n",
    "    \n",
    "class MarkDuplicatesTransformer(TransformerMixin):\n",
    "    def __init__(self,cols,include=True):\n",
    "        self.cols = cols\n",
    "        self.include = include\n",
    "\n",
    "    def transform(self, X, **transform_params):  \n",
    "        print(\"Duplicates\")\n",
    "        if self.include:\n",
    "            X2 = X[self.cols]\n",
    "        else:\n",
    "            X2 = X.drop( self.cols, axis = 1 ,errors='ignore')\n",
    "        return (pd.Series(X2.duplicated()|X2.duplicated(keep=\"last\")).apply(int))[:,None]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self        \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "class FeatureVecotrizer(TransformerMixin):\n",
    "    def __init__(self,cols,include=True):\n",
    "        self.cols = cols\n",
    "        self.include = include\n",
    "\n",
    "    def transform(self, X,y=None, **transform_params):\n",
    "        print(\"Vectorizer\")\n",
    "        if self.include:\n",
    "            x_cat_train = X[self.cols]\n",
    "            x_num_train = X.drop( self.cols, axis = 1 )\n",
    "        else:\n",
    "            x_num_train = X[self.cols]\n",
    "            x_cat_train = X.drop( self.cols, axis = 1 )\n",
    "        \n",
    "        x_cat_train.fillna( 'NA', inplace = True )\n",
    "        vec_x_cat_train  =pd.get_dummies(x_cat_train)\n",
    "        return vec_x_cat_train\n",
    "\n",
    "    def fit(self, X,y=None, **fit_params):\n",
    "        x_cat_train = X[self.cols]\n",
    "        x_cat_train.fillna( 'NA', inplace = True )\n",
    "        x_cat_train = x_cat_train.T.to_dict().values()\n",
    "        return  self\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PapaDocNeuralNetworkModel(Sequential):\n",
    "    \n",
    "    def __init__(self,hn=32,dp=0.5,layers=1,epochs=1,batches=64,verbose=0,*args,**kwargs):\n",
    "        self.hn = hn\n",
    "        self.dp = dp\n",
    "        self.Nlayers = layers\n",
    "        self.epochs=epochs\n",
    "        self.batches = batches\n",
    "        self.verbose = verbose\n",
    "        super(PapaDocNeuralNetworkModel,self).__init__(*args,**kwargs)\n",
    "    \n",
    "    def fit(self,X_train,y_train,X_test=None,y_test=None,*args,**kwargs):\n",
    "        y_train=y_train.astype('category')\n",
    "        input_dim=X_train.shape[1]\n",
    "        output_dim=len(y_train.unique())\n",
    "        Y_train=np_utils.to_categorical(y_train.cat.rename_categories(range(len(y_train.unique()))))\n",
    "        self.add(Dense(input_dim=input_dim, output_dim=self.hn, init='glorot_uniform'))\n",
    "        self.add(PReLU(input_shape=(self.hn,)))\n",
    "        self.add(Dropout(self.dp))\n",
    "        for i in range(self.Nlayers):\n",
    "            self.add(Dense(input_dim=self.hn, output_dim=self.hn, init='glorot_uniform'))\n",
    "            self.add(PReLU(input_shape=(self.hn,)))\n",
    "            self.add(BatchNormalization())\n",
    "            self.add(Dropout(self.dp))\n",
    "\n",
    "        self.add(Dense(input_dim=self.hn, output_dim=output_dim, init='glorot_uniform'))\n",
    "        self.add(Activation('softmax'))\n",
    "        self.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "        if X_test is not None:\n",
    "            X_test=X_test.as_matrix()\n",
    "            y_test=y_test.astype('category')\n",
    "            Y_test=np_utils.to_categorical(y_test.cat.rename_categories(range(len(y_test.unique()))))\n",
    "            super(PapaDocNeuralNetworkModel,self).fit(X_train, Y_train, nb_epoch=self.epochs, \\\n",
    "                            batch_size=self.batches,verbose=self.verbose,\\\n",
    "                              validation_data=(X_test,Y_test),*args,**kwargs)\n",
    "        else:\n",
    "            super(PapaDocNeuralNetworkModel,self).fit(X_train, Y_train, nb_epoch=self.epochs, \\\n",
    "                                                      batch_size=self.batches,verbose=self.verbose,*args,**kwargs)\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_EPOCHS=20\n",
    "N_HN=128\n",
    "N_LAYERS=1\n",
    "DP=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler\n",
      "Dates\n",
      "Intersection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda2/lib/python2.7/site-packages/pandas/core/frame.py:2756: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogOdds\n",
      "['Dates', 'Category', 'Descript', 'DayOfWeek', 'PdDistrict', 'Resolution', 'Address', 'X', 'Y']\n",
      "Duplicates\n",
      "Seasons\n"
     ]
    }
   ],
   "source": [
    "#Kyles LR Model\n",
    "\n",
    "f = FeatureUnion([\n",
    "                    (\"XY\",ScalerTransform([\"X\",\"Y\"])), \\\n",
    "                    (\"Vectorizer\",FeatureVecotrizer(['PdDistrict','DayOfWeek'])),\\\n",
    "                    ],n_jobs=3)\n",
    "p = Pipeline(steps=[(\"FeatureEngineering\",f),\\\n",
    "                    (\"Model\",LogisticRegression(C=.01))\n",
    "])\n",
    "\n",
    "#Papadocs Neural Model\n",
    "f = FeatureUnion([\n",
    "                    (\"XY\",ScalerTransform([\"X\",\"Y\"])), \\\n",
    "                    (\"DateToTime\",DatesTransformer()), \\\n",
    "                    (\"Intersection\",AddIsIntersectionTransformer()),\\\n",
    "                    (\"Vectorizer\",FeatureVecotrizer(['PdDistrict','DayOfWeek'])),\\\n",
    "                    #(\"LogsOdds\",Pipeline([\\\n",
    "                               # (\"Street\",StreetNamesTransformer()),\\\n",
    "                                #(\"LogOdds\",LogOddsTransformer([\"PdDistrict\",\"street1\"]))\\\n",
    "                    #])),\\\n",
    "                    (\"LogOdds\",LogOddsTransformer([\"Address\"])),\\\n",
    "\n",
    "                    (\"MarkDuplicates\",MarkDuplicatesTransformer([\"PdDistrict\",\"DayOfWeek\",\"Dates\",\"Address\"])),\\\n",
    "                    (\"Seasons\",SeasonsTransformer())\n",
    "                    ],n_jobs=3)\n",
    "p = Pipeline(steps=[(\"FeatureEngineering\",f),\\\n",
    "                    (\"ScaleEverything\",preprocessing.StandardScaler()),\\\n",
    "                    (\"Model\",PapaDocNeuralNetworkModel(hn=N_HN,layers=N_LAYERS,epochs=N_EPOCHS,verbose=2,dp=DP))\n",
    "])\n",
    "\n",
    "\n",
    "model = p.fit(train_data,train_labels.astype('category'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"train\", log_loss(train_labels.astype('category'), model.predict_proba(train_data))\n",
    "print \"test\", log_loss(dev_labels.astype('category'), model.predict_proba(dev_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Begin Papadocs Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_data(df,logodds,logoddsPA):\n",
    "    feature_list=df.columns.tolist()\n",
    "    if \"Descript\" in feature_list:\n",
    "        feature_list.remove(\"Descript\")\n",
    "    if \"Resolution\" in feature_list:\n",
    "        feature_list.remove(\"Resolution\")\n",
    "    if \"Category\" in feature_list:\n",
    "        feature_list.remove(\"Category\")\n",
    "    if \"Id\" in feature_list:\n",
    "        feature_list.remove(\"Id\")\n",
    "    cleanData=df[feature_list]\n",
    "    cleanData.index=range(len(df))\n",
    "    print \"Creating address features\"\n",
    "    address_features=cleanData[\"Address\"].apply(lambda x: logodds[x])\n",
    "\n",
    "    \n",
    "    address_features.columns=[\"logodds\"+str(x) for x in range(len(address_features.columns))]\n",
    "    address_features[\"logoddsPA\"]=cleanData[\"Address\"].apply(lambda x: logoddsPA[x])\n",
    "\n",
    "    print \"Parsing dates\"\n",
    "    cleanData[\"Time\"], cleanData[\"Day\"], cleanData[\"Month\"], cleanData[\"Year\"]=zip(*cleanData[\"Dates\"].apply(parse_time))\n",
    "#     dummy_ranks_DAY = pd.get_dummies(cleanData['DayOfWeek'], prefix='DAY')\n",
    "    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "#     cleanData[\"DayOfWeek\"]=cleanData[\"DayOfWeek\"].apply(lambda x: days.index(x)/float(len(days)))\n",
    "    print \"Creating one-hot variables\"\n",
    "    dummy_ranks_PD = pd.get_dummies(cleanData['PdDistrict'], prefix='PD')\n",
    "    dummy_ranks_DAY = pd.get_dummies(cleanData[\"DayOfWeek\"], prefix='DAY')\n",
    "    cleanData[\"IsInterection\"]=cleanData[\"Address\"].apply(lambda x: 1 if \"/\" in x else 0)\n",
    "    cleanData[\"logoddsPA\"]=cleanData[\"Address\"].apply(lambda x: logoddsPA[x])\n",
    "    \n",
    "    print \"droping processed columns\"\n",
    "    cleanData=cleanData.drop(\"PdDistrict\",axis=1)\n",
    "    cleanData=cleanData.drop(\"DayOfWeek\",axis=1)\n",
    "    cleanData=cleanData.drop(\"Address\",axis=1)\n",
    "    cleanData=cleanData.drop(\"Dates\",axis=1)\n",
    "    feature_list=cleanData.columns.tolist()\n",
    "    print \"joining one-hot features\"\n",
    "    features = cleanData[feature_list].join(dummy_ranks_PD.ix[:,:]).join(dummy_ranks_DAY.ix[:,:]).join(address_features.ix[:,:])\n",
    "    print \"creating new features\"\n",
    "    features[\"IsDup\"]=pd.Series(features.duplicated()|features.duplicated(keep=\"last\")).apply(int)\n",
    "    features[\"Awake\"]=features[\"Time\"].apply(lambda x: 1 if (x==0 or (x>=8 and x<=23)) else 0)\n",
    "    features[\"Summer\"], features[\"Fall\"], features[\"Winter\"], features[\"Spring\"]=zip(*features[\"Month\"].apply(get_season))\n",
    "    if \"Category\" in df.columns:\n",
    "        labels = df[\"Category\"].astype('category')\n",
    "#         label_names=labels.unique()\n",
    "#         labels=labels.cat.rename_categories(range(len(label_names)))\n",
    "    else:\n",
    "        labels=None\n",
    "    return features,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is slower than it needs to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "addresses=sorted(trainDF[\"Address\"].unique())\n",
    "categories=sorted(trainDF[\"Category\"].unique())\n",
    "C_counts=trainDF.groupby([\"Category\"]).size()\n",
    "A_C_counts=trainDF.groupby([\"Address\",\"Category\"]).size()\n",
    "A_counts=trainDF.groupby([\"Address\"]).size()\n",
    "logodds={}\n",
    "logoddsPA={}\n",
    "MIN_CAT_COUNTS=2\n",
    "default_logodds=np.log(C_counts/len(trainDF))-np.log(1.0-C_counts/float(len(trainDF)))\n",
    "for addr in addresses:\n",
    "    PA=A_counts[addr]/float(len(trainDF))\n",
    "    logoddsPA[addr]=np.log(PA)-np.log(1.-PA)\n",
    "    logodds[addr]=deepcopy(default_logodds)\n",
    "    for cat in A_C_counts[addr].keys():\n",
    "        if (A_C_counts[addr][cat]>MIN_CAT_COUNTS) and A_C_counts[addr][cat]<A_counts[addr]:\n",
    "            PA=A_C_counts[addr][cat]/float(A_counts[addr])\n",
    "            logodds[addr][categories.index(cat)]=np.log(PA)-np.log(1.0-PA)\n",
    "    logodds[addr]=pd.Series(logodds[addr])\n",
    "    logodds[addr].index=range(len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "features, labels=parse_data(trainDF,logodds,logoddsPA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print features.columns.tolist()\n",
    "print features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_feature_list=[\"Time\",\"Day\",\"Month\",\"Year\",\"DayOfWeek\"]\n",
    "collist=features.columns.tolist()\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(features)\n",
    "features[collist]=scaler.transform(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#new_PCA=PCA(n_components=60)\n",
    "#new_PCA.fit(features)\n",
    "#plt.plot(new_PCA.explained_variance_ratio_)\n",
    "#plt.yscale('log')\n",
    "#plt.title(\"PCA explained ratio of features\")\n",
    "#print new_PCA.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.plot(new_PCA.explained_variance_ratio_.cumsum())\n",
    "#plt.title(\"cumsum of PCA explained ratio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA is interesting, here to play with it more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(labels, train_size=0.5,random_state=0)\n",
    "for train_index, test_index in sss:\n",
    "    features_train,features_test=features.iloc[train_index],features.iloc[test_index]\n",
    "    labels_train,labels_test=labels[train_index],labels[test_index]\n",
    "    \n",
    "\n",
    "features_test.index=range(len(features_test))\n",
    "features_train.index=range(len(features_train))\n",
    "labels_train.index=range(len(labels_train))\n",
    "labels_test.index=range(len(labels_test))\n",
    "features.index=range(len(features))\n",
    "labels.index=range(len(labels))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_and_fit_model(X_train,y_train,X_test=None,y_test=None,hn=32,dp=0.5,layers=1,epochs=1,batches=64,verbose=0):\n",
    "    input_dim=X_train.shape[1]\n",
    "    output_dim=len(labels_train.unique())\n",
    "    Y_train=np_utils.to_categorical(y_train.cat.rename_categories(range(len(y_train.unique()))))\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=input_dim, output_dim=hn, init='glorot_uniform'))\n",
    "    model.add(PReLU(input_shape=(hn,)))\n",
    "    model.add(Dropout(dp))\n",
    "\n",
    "    for i in range(layers):\n",
    "        model.add(Dense(input_dim=hn, output_dim=hn, init='glorot_uniform'))\n",
    "        model.add(PReLU(input_shape=(hn,)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dp))\n",
    "\n",
    "    model.add(Dense(input_dim=hn, output_dim=output_dim, init='glorot_uniform'))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    \n",
    "    if X_test is not None:\n",
    "        Y_test=np_utils.to_categorical(y_test.cat.rename_categories(range(len(y_test.unique()))))\n",
    "        fitting=model.fit(X_train, Y_train, nb_epoch=epochs, batch_size=batches,verbose=verbose,validation_data=(X_test,Y_test))\n",
    "        test_score = log_loss(y_test, model.predict_proba(X_test,verbose=0))\n",
    "    else:\n",
    "        model.fit(X_train, Y_train, nb_epoch=epochs, batch_size=batches,verbose=verbose)\n",
    "        fitting=0\n",
    "        test_score = 0\n",
    "    return test_score, fitting, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#score, fitting, model = build_and_fit_model(features_train.as_matrix(),labels_train,hn=N_HN,layers=N_LAYERS,epochs=N_EPOCHS,verbose=2,dp=DP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print \"all\", log_loss(labels, model.predict_proba(features.as_matrix(),verbose=0))\n",
    "#print \"train\", log_loss(labels_train, model.predict_proba(features_train.as_matrix(),verbose=0))\n",
    "#print \"test\", log_loss(labels_test, model.predict_proba(features_test.as_matrix(),verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score, fitting, model = build_and_fit_model(features.as_matrix(),labels,hn=N_HN,layers=N_LAYERS,\n",
    "                                            epochs=N_EPOCHS,verbose=2,dp=DP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"all\", log_loss(labels, model.predict_proba(features.as_matrix(),verbose=0))\n",
    "print \"train\", log_loss(labels_train, model.predict_proba(features_train.as_matrix(),verbose=0))\n",
    "print \"test\", log_loss(labels_test, model.predict_proba(features_test.as_matrix(),verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testDF=pd.read_csv(\"data/test.csv\")\n",
    "testDF[[\"X\",\"Y\"]]=xy_scaler.transform(testDF[[\"X\",\"Y\"]])\n",
    "#set outliers to 0\n",
    "testDF[\"X\"]=testDF[\"X\"].apply(lambda x: 0 if abs(x)>5 else x)\n",
    "testDF[\"Y\"]=testDF[\"Y\"].apply(lambda y: 0 if abs(y)>5 else y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_addresses=sorted(testDF[\"Address\"].unique())\n",
    "new_A_counts=testDF.groupby(\"Address\").size()\n",
    "only_new=set(new_addresses+addresses)-set(addresses)\n",
    "only_old=set(new_addresses+addresses)-set(new_addresses)\n",
    "in_both=set(new_addresses).intersection(addresses)\n",
    "for addr in only_new:\n",
    "    PA=new_A_counts[addr]/float(len(testDF)+len(trainDF))\n",
    "    logoddsPA[addr]=np.log(PA)-np.log(1.-PA)\n",
    "    logodds[addr]=deepcopy(default_logodds)\n",
    "    logodds[addr].index=range(len(categories))\n",
    "for addr in in_both:\n",
    "    PA=(A_counts[addr]+new_A_counts[addr])/float(len(testDF)+len(trainDF))\n",
    "    logoddsPA[addr]=np.log(PA)-np.log(1.-PA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_sub, _=parse_data(testDF,logodds,logoddsPA)\n",
    "# scaler.fit(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collist=features_sub.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_sub[collist]=scaler.transform(features_sub[collist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predDF=pd.DataFrame(model.predict_proba(features_sub.as_matrix(),verbose=0),columns=sorted(labels.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predDF.to_csv(\"crimeSF_NN_logodds.csv\",index_label=\"Id\",na_rep=\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
