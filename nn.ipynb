{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import accelerate\n",
    "#import numbapro\n",
    "import mkl\n",
    "#import iopro\n",
    "\n",
    "# General libraries.\n",
    "from __future__ import division\n",
    "from collections import Counter\n",
    "import csv\n",
    "import dateutil\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SK-learn libraries for preprocessing.\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder # for integer values\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.mixture import GMM\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = \"data\"\n",
    "submissions_path = \"submissions\"\n",
    "if not data_path or not submissions_path:\n",
    "    raise Exception(\"Set the data and submission paths in competition_utilities.py!\")\n",
    "\n",
    "def parse_date_maybe_null(date):\n",
    "    if date:\n",
    "        return dateutil.parser.parse(date)\n",
    "    return None\n",
    "\n",
    "df_converters = {\"Dates\": dateutil.parser.parse}\n",
    "\n",
    "def get_reader(file_name=\"train.csv\"):\n",
    "    reader = csv.reader(open(os.path.join(data_path, file_name)))\n",
    "    header = reader.next()\n",
    "    return reader\n",
    "\n",
    "def get_header(file_name=\"train.csv\"):\n",
    "    reader = csv.reader(open(os.path.join(data_path, file_name)))\n",
    "    header = reader.next()\n",
    "    return header\n",
    "\n",
    "def get_dataframe(file_name=\"train.csv\"):\n",
    "    return pd.io.parsers.read_csv(os.path.join(data_path, file_name), converters = df_converters)\n",
    "\n",
    "    \n",
    "def write_submission(file_name, predictions):\n",
    "    writer = csv.writer(open(os.path.join(submissions_path, file_name), \"w\"), lineterminator=\"\\n\")\n",
    "    writer.writerows(predictions)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Dates</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-05-10 23:59:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>2000 Block of THOMAS AV</td>\n",
       "      <td>-122.399588</td>\n",
       "      <td>37.735051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-10 23:51:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>3RD ST / REVERE AV</td>\n",
       "      <td>-122.391523</td>\n",
       "      <td>37.732432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-05-10 23:50:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>2000 Block of GOUGH ST</td>\n",
       "      <td>-122.426002</td>\n",
       "      <td>37.792212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-05-10 23:45:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>INGLESIDE</td>\n",
       "      <td>4700 Block of MISSION ST</td>\n",
       "      <td>-122.437394</td>\n",
       "      <td>37.721412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-05-10 23:45:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>INGLESIDE</td>\n",
       "      <td>4700 Block of MISSION ST</td>\n",
       "      <td>-122.437394</td>\n",
       "      <td>37.721412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id               Dates DayOfWeek PdDistrict                   Address  \\\n",
       "0   0 2015-05-10 23:59:00    Sunday    BAYVIEW   2000 Block of THOMAS AV   \n",
       "1   1 2015-05-10 23:51:00    Sunday    BAYVIEW        3RD ST / REVERE AV   \n",
       "2   2 2015-05-10 23:50:00    Sunday   NORTHERN    2000 Block of GOUGH ST   \n",
       "3   3 2015-05-10 23:45:00    Sunday  INGLESIDE  4700 Block of MISSION ST   \n",
       "4   4 2015-05-10 23:45:00    Sunday  INGLESIDE  4700 Block of MISSION ST   \n",
       "\n",
       "            X          Y  \n",
       "0 -122.399588  37.735051  \n",
       "1 -122.391523  37.732432  \n",
       "2 -122.426002  37.792212  \n",
       "3 -122.437394  37.721412  \n",
       "4 -122.437394  37.721412  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestD = get_dataframe(\"test.csv\")\n",
    "TestD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = TestD.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Category</th>\n",
       "      <th>Descript</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>WARRANTS</td>\n",
       "      <td>WARRANT ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-13 23:33:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>VANNESS AV / GREENWICH ST</td>\n",
       "      <td>-122.424363</td>\n",
       "      <td>37.800414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>GRAND THEFT FROM LOCKED AUTO</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1500 Block of LOMBARD ST</td>\n",
       "      <td>-122.426995</td>\n",
       "      <td>37.800873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>GRAND THEFT FROM LOCKED AUTO</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>PARK</td>\n",
       "      <td>NONE</td>\n",
       "      <td>100 Block of BRODERICK ST</td>\n",
       "      <td>-122.438738</td>\n",
       "      <td>37.771541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Dates        Category                      Descript  \\\n",
       "0 2015-05-13 23:53:00        WARRANTS                WARRANT ARREST   \n",
       "1 2015-05-13 23:53:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n",
       "2 2015-05-13 23:33:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n",
       "3 2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO   \n",
       "4 2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO   \n",
       "\n",
       "   DayOfWeek PdDistrict      Resolution                    Address  \\\n",
       "0  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n",
       "1  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n",
       "2  Wednesday   NORTHERN  ARREST, BOOKED  VANNESS AV / GREENWICH ST   \n",
       "3  Wednesday   NORTHERN            NONE   1500 Block of LOMBARD ST   \n",
       "4  Wednesday       PARK            NONE  100 Block of BRODERICK ST   \n",
       "\n",
       "            X          Y  \n",
       "0 -122.425892  37.774599  \n",
       "1 -122.425892  37.774599  \n",
       "2 -122.424363  37.800414  \n",
       "3 -122.426995  37.800873  \n",
       "4 -122.438738  37.771541  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainD = get_dataframe(\"train.csv\")\n",
    "TrainD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = TrainD.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "['ARSON', 'ASSAULT', 'BAD CHECKS', 'BRIBERY', 'BURGLARY', 'DISORDERLY CONDUCT', 'DRIVING UNDER THE INFLUENCE', 'DRUG/NARCOTIC', 'DRUNKENNESS', 'EMBEZZLEMENT', 'EXTORTION', 'FAMILY OFFENSES', 'FORGERY/COUNTERFEITING', 'FRAUD', 'GAMBLING', 'KIDNAPPING', 'LARCENY/THEFT', 'LIQUOR LAWS', 'LOITERING', 'MISSING PERSON', 'NON-CRIMINAL', 'OTHER OFFENSES', 'PORNOGRAPHY/OBSCENE MAT', 'PROSTITUTION', 'RECOVERED VEHICLE', 'ROBBERY', 'RUNAWAY', 'SECONDARY CODES', 'SEX OFFENSES FORCIBLE', 'SEX OFFENSES NON FORCIBLE', 'STOLEN PROPERTY', 'SUICIDE', 'SUSPICIOUS OCC', 'TREA', 'TRESPASS', 'VANDALISM', 'VEHICLE THEFT', 'WARRANTS', 'WEAPON LAWS']\n"
     ]
    }
   ],
   "source": [
    "number_of_categories = train_data['Category'].nunique()\n",
    "category_names = sorted(train_data['Category'].unique())\n",
    "print number_of_categories\n",
    "print category_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                       WARRANTS\n",
      "1                 OTHER OFFENSES\n",
      "2                 OTHER OFFENSES\n",
      "3                  LARCENY/THEFT\n",
      "4                  LARCENY/THEFT\n",
      "5                  LARCENY/THEFT\n",
      "6                  VEHICLE THEFT\n",
      "7                  VEHICLE THEFT\n",
      "8                  LARCENY/THEFT\n",
      "9                  LARCENY/THEFT\n",
      "10                 LARCENY/THEFT\n",
      "11                OTHER OFFENSES\n",
      "12                     VANDALISM\n",
      "13                 LARCENY/THEFT\n",
      "14                  NON-CRIMINAL\n",
      "15                  NON-CRIMINAL\n",
      "16                       ROBBERY\n",
      "17                       ASSAULT\n",
      "18                OTHER OFFENSES\n",
      "19                  NON-CRIMINAL\n",
      "20                 LARCENY/THEFT\n",
      "21                       ROBBERY\n",
      "22                      WARRANTS\n",
      "23                  NON-CRIMINAL\n",
      "24                 LARCENY/THEFT\n",
      "25                  NON-CRIMINAL\n",
      "26                 LARCENY/THEFT\n",
      "27                 LARCENY/THEFT\n",
      "28                 LARCENY/THEFT\n",
      "29                OTHER OFFENSES\n",
      "                   ...          \n",
      "878019            OTHER OFFENSES\n",
      "878020            OTHER OFFENSES\n",
      "878021                 VANDALISM\n",
      "878022             VEHICLE THEFT\n",
      "878023             LARCENY/THEFT\n",
      "878024            OTHER OFFENSES\n",
      "878025            OTHER OFFENSES\n",
      "878026                  WARRANTS\n",
      "878027                  WARRANTS\n",
      "878028                   ASSAULT\n",
      "878029            OTHER OFFENSES\n",
      "878030     SEX OFFENSES FORCIBLE\n",
      "878031                   ASSAULT\n",
      "878032            OTHER OFFENSES\n",
      "878033                 VANDALISM\n",
      "878034                  TRESPASS\n",
      "878035                   ASSAULT\n",
      "878036             LARCENY/THEFT\n",
      "878037                 VANDALISM\n",
      "878038                  WARRANTS\n",
      "878039            OTHER OFFENSES\n",
      "878040                   ASSAULT\n",
      "878041            OTHER OFFENSES\n",
      "878042                   ASSAULT\n",
      "878043            OTHER OFFENSES\n",
      "878044                   ROBBERY\n",
      "878045             LARCENY/THEFT\n",
      "878046             LARCENY/THEFT\n",
      "878047                 VANDALISM\n",
      "878048    FORGERY/COUNTERFEITING\n",
      "Name: Category, dtype: category\n",
      "Categories (39, object): [ARSON, ASSAULT, BAD CHECKS, BRIBERY, ..., VANDALISM, VEHICLE THEFT, WARRANTS, WEAPON LAWS]\n"
     ]
    }
   ],
   "source": [
    "labels = train_data[\"Category\"].astype('category')\n",
    "if \"Category\" in train_data.columns:\n",
    "    del train_data['Category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAKE REGIONS FROM lat/long "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original max and min values\n",
      "---------------------------\n",
      "(-122.51364206429, -120.5, 37.707879022413501, 90.0)\n",
      "New max and min values\n",
      "---------------------------\n",
      "(-122.51364206429, -122.3, 37.707879022413501, 37.799999999999997)\n"
     ]
    }
   ],
   "source": [
    "# Train data:\n",
    "\n",
    "min_x, max_x = np.min(train_data['X']), np.max(train_data['X'])\n",
    "min_y, max_y = np.min(train_data['Y']), np.max(train_data['Y'])\n",
    "print \"Original max and min values\"\n",
    "print \"---------------------------\"\n",
    "print (min_x, max_x,min_y, max_y)\n",
    "\n",
    "\n",
    "# fix invalid values:\n",
    "train_data.loc[train_data['X'] > -122.3, 'X'] = -122.3\n",
    "train_data.loc[train_data['Y'] > 37.8, 'Y'] = 37.8\n",
    "\n",
    "grid_size = 10\n",
    "grid_width = np.max(train_data['X']) - np.min(train_data['X'])\n",
    "grid_height = np.max(train_data['Y']) - np.min(train_data['Y'])\n",
    "\n",
    "x_interval = grid_width/grid_size\n",
    "y_interval = grid_height/grid_size\n",
    "\n",
    "min_x, max_x = np.min(train_data['X']), np.max(train_data['X'])\n",
    "min_y, max_y = np.min(train_data['Y']), np.max(train_data['Y'])\n",
    "\n",
    "train_data['region'] = (10*(np.ceil((train_data['X'] - min_x)/x_interval)) + (np.ceil((train_data['Y'] - min_y)/y_interval))).astype(int)\n",
    "\n",
    "print \"New max and min values\"\n",
    "print \"---------------------------\"\n",
    "print (min_x, max_x, min_y, max_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original max and min values\n",
      "---------------------------\n",
      "(-122.51364206429, -120.5, 37.707879022413501, 90.0)\n",
      "New max and min values\n",
      "---------------------------\n",
      "(-122.51364206429, -122.3, 37.707879022413501, 37.799999999999997)\n"
     ]
    }
   ],
   "source": [
    "# Test data:\n",
    "\n",
    "min_x, max_x = np.min(test_data.loc[:,'X']), np.max(test_data.loc[:,'X'])\n",
    "min_y, max_y = np.min(test_data.loc[:,'Y']), np.max(test_data.loc[:,'Y'])\n",
    "\n",
    "print \"Original max and min values\"\n",
    "print \"---------------------------\"\n",
    "print (min_x, max_x,min_y, max_y)\n",
    "\n",
    "test_data.loc[test_data['X'] > -122.3, 'X'] = -122.3\n",
    "test_data.loc[test_data['Y'] > 37.8, 'Y'] = 37.8\n",
    "\n",
    "grid_size = 10\n",
    "grid_width = np.max(test_data.loc[:,'X']) - np.min(test_data.loc[:,'X'])\n",
    "grid_height = np.max(test_data.loc[:,'Y']) - np.min(test_data.loc[:,'Y'])\n",
    "\n",
    "x_interval = grid_width/grid_size\n",
    "y_interval = grid_height/grid_size\n",
    "\n",
    "min_x, max_x = np.min(test_data.loc[:,'X']), np.max(test_data.loc[:,'X'])\n",
    "min_y, max_y = np.min(test_data.loc[:,'Y']), np.max(test_data.loc[:,'Y'])\n",
    "\n",
    "test_data['region'] = (10*(np.ceil((test_data['X'] - min_x)/x_interval)) + (np.ceil((test_data['Y'] - min_y)/y_interval))).astype(int)\n",
    "\n",
    "print \"New max and min values\"\n",
    "print \"---------------------------\"\n",
    "print (min_x, max_x, min_y, max_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARSE THE DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data.loc[:,'Hour'] = (train_data.loc[:,'Dates']).dt.hour\n",
    "train_data.loc[:,'Month'] = (train_data.loc[:,'Dates']).dt.month\n",
    "train_data.loc[:,'Year'] = (train_data.loc[:,'Dates']).dt.year\n",
    "train_data.loc[:,'Day'] = (train_data.loc[:,'Dates']).dt.day\n",
    "\n",
    "\n",
    "test_data['Hour'] = (test_data['Dates']).dt.hour\n",
    "test_data['Month'] = (test_data['Dates']).dt.month\n",
    "test_data['Year'] = (test_data['Dates']).dt.year\n",
    "test_data['Day'] = (test_data['Dates']).dt.day\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REMOVE UNUSED COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del train_data['Dates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del train_data['Descript']\n",
    "del train_data['X']\n",
    "del train_data['Y']\n",
    "del train_data['Address']\n",
    "del train_data['Resolution']\n",
    "\n",
    "del test_data['Dates']\n",
    "del test_data['X']\n",
    "del test_data['Y']\n",
    "del test_data['Address']\n",
    "del test_data['Id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAKE DUMMY VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "days = train_data.loc[:,'DayOfWeek'].unique()\n",
    "le.fit(days)\n",
    "train_data.loc[:,'DayOfWeek'] = le.transform(train_data.loc[:,'DayOfWeek']) \n",
    "\n",
    "\n",
    "days = test_data.loc[:,'DayOfWeek'].unique()\n",
    "le.fit(days)\n",
    "test_data.loc[:,'DayOfWeek'] = le.transform(test_data.loc[:,'DayOfWeek'])\n",
    "\n",
    "\n",
    "district = train_data.loc[:,'PdDistrict'].unique()\n",
    "le.fit(district)\n",
    "train_data.loc[:,'PdDistrict'] = le.transform(train_data.loc[:,'PdDistrict']) \n",
    "\n",
    "\n",
    "district = test_data.loc[:,'PdDistrict'].unique()\n",
    "le.fit(district)\n",
    "test_data.loc[:,'PdDistrict'] = le.transform(test_data.loc[:,'PdDistrict']) \n",
    "\n",
    "\n",
    "district = train_data.loc[:,'region'].unique()\n",
    "le.fit(district)\n",
    "train_data.loc[:,'region'] = le.transform(train_data.loc[:,'region']) \n",
    "\n",
    "\n",
    "district = test_data.loc[:,'region'].unique()\n",
    "le.fit(district)\n",
    "test_data.loc[:,'region'] = le.transform(test_data.loc[:,'region']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# NOT USING THIS - Scale instead.\n",
    "enc = OneHotEncoder()\n",
    "train_data_onehot = enc.fit_transform(train_data) \n",
    "test_data_onehot = enc.fit_transform(test_data)\n",
    "\n",
    "# print train_data_onehot.toarray()\n",
    "print train_data_onehot.shape\n",
    "\n",
    "#print test_data_onehot.toarray()\n",
    "print test_data_onehot.shape\n",
    "\n",
    "#print enc.n_values_\n",
    "#print enc.feature_indices_\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collist=train_data.columns.tolist()\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data[collist]=scaler.transform(train_data)\n",
    "\n",
    "collisttest=test_data.columns.tolist()\n",
    "scalertest = preprocessing.StandardScaler()\n",
    "scalertest.fit(test_data)\n",
    "test_data[collisttest]=scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make train and dev sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(labels, train_size=0.5)\n",
    "\n",
    "for train_index, dev_index in sss:\n",
    "    X_train, X_dev = train_data.iloc[train_index], train_data.iloc[dev_index]\n",
    "    y_train, y_dev = labels[train_index],labels[dev_index]\n",
    "    \n",
    "X_train.index=range(len(X_train))\n",
    "X_dev.index=range(len(X_dev))\n",
    "\n",
    "y_train.index=range(len(y_train))\n",
    "y_dev.index=range(len(y_dev))\n",
    "\n",
    "train_data.index=range(len(train_data))\n",
    "labels.index=range(len(labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier()\n",
    "model = classifier.fit(X_train, y_train)\n",
    "print model.score(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier()\n",
    "model = classifier.fit(X_train, y_train)\n",
    "print model.score(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.202750166276\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "model = classifier.fit(X_train, y_train)\n",
    "print model.score(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = BernoulliNB()\n",
    "model = classifier.fit(X_train, y_train)\n",
    "print model.score(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = MultinomialNB()\n",
    "model = classifier.fit(X_train, y_train)\n",
    "print model.score(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predict and write file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_proba(test_data)\n",
    "withId  = np.column_stack((map(str,xrange(test_data.shape[0])),predictions))\n",
    "towrite = np.row_stack(([\"Id\"] + sorted(y_train.unique()),withId))\n",
    "\n",
    "print(towrite)\n",
    "write_submission('submission_MultiNB.csv', towrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(439024,)\n",
      "(439024, 7)\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train.astype('category')\n",
    "y_train = y_train.cat.rename_categories(range(len(y_train.unique())))\n",
    "\n",
    "print y_train.shape\n",
    "print X_train.shape\n",
    "\n",
    "y_dev = y_dev.astype('category')\n",
    "y_dev = y_dev.cat.rename_categories(range(len(y_dev.unique())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "265600/439024 [=================>............] - ETA: 10s - loss: 2.7416 - acc: 7.3419e-04"
     ]
    }
   ],
   "source": [
    "output_dim = 39\n",
    "input_dim = X_train.shape[1]\n",
    "Nlayers = 1\n",
    "Nepoch = 20\n",
    "dp = 0.5\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim=input_dim, output_dim=output_dim, init='glorot_uniform'))\n",
    "model.add(PReLU(input_shape=(input_dim,)))\n",
    "model.add(Dropout(dp))\n",
    "\n",
    "for i in range(Nlayers):\n",
    "    model.add(Dense(input_dim=input_dim, output_dim=output_dim,init='glorot_uniform'))\n",
    "    model.add(PReLU(input_shape=(input_dim,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dp))\n",
    "\n",
    "model.add(Dense(input_dim=input_dim, output_dim=output_dim,init='glorot_uniform'))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "\n",
    "#model.fit(train_data_onehot.toarray(), y_train, nb_epoch=Nepoch, batch_size=32)\n",
    "model.fit(X_train.as_matrix() , y_train, nb_epoch=Nepoch, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
