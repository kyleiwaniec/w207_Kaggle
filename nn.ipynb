{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import accelerate\n",
    "#import numbapro\n",
    "import mkl\n",
    "#import iopro\n",
    "\n",
    "# General libraries.\n",
    "from __future__ import division\n",
    "from collections import Counter\n",
    "import csv\n",
    "import dateutil\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SK-learn libraries for preprocessing.\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder # for integer values\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.mixture import GMM\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "from copy import deepcopy\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = \"data\"\n",
    "submissions_path = \"submissions\"\n",
    "if not data_path or not submissions_path:\n",
    "    raise Exception(\"Set the data and submission paths in competition_utilities.py!\")\n",
    "\n",
    "def parse_date_maybe_null(date):\n",
    "    if date:\n",
    "        return dateutil.parser.parse(date)\n",
    "    return None\n",
    "\n",
    "df_converters = {\"Dates\": dateutil.parser.parse}\n",
    "\n",
    "def get_reader(file_name=\"train.csv\"):\n",
    "    reader = csv.reader(open(os.path.join(data_path, file_name)))\n",
    "    header = reader.next()\n",
    "    return reader\n",
    "\n",
    "def get_header(file_name=\"train.csv\"):\n",
    "    reader = csv.reader(open(os.path.join(data_path, file_name)))\n",
    "    header = reader.next()\n",
    "    return header\n",
    "\n",
    "def get_dataframe(file_name=\"train.csv\"):\n",
    "    return pd.io.parsers.read_csv(os.path.join(data_path, file_name), converters = df_converters)\n",
    "\n",
    "    \n",
    "def write_submission(file_name, predictions):\n",
    "    writer = csv.writer(open(os.path.join(submissions_path, file_name), \"w\"), lineterminator=\"\\n\")\n",
    "    writer.writerows(predictions)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Dates</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-05-10 23:59:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>2000 Block of THOMAS AV</td>\n",
       "      <td>-122.399588</td>\n",
       "      <td>37.735051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-10 23:51:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>3RD ST / REVERE AV</td>\n",
       "      <td>-122.391523</td>\n",
       "      <td>37.732432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-05-10 23:50:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>2000 Block of GOUGH ST</td>\n",
       "      <td>-122.426002</td>\n",
       "      <td>37.792212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-05-10 23:45:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>INGLESIDE</td>\n",
       "      <td>4700 Block of MISSION ST</td>\n",
       "      <td>-122.437394</td>\n",
       "      <td>37.721412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-05-10 23:45:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>INGLESIDE</td>\n",
       "      <td>4700 Block of MISSION ST</td>\n",
       "      <td>-122.437394</td>\n",
       "      <td>37.721412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id               Dates DayOfWeek PdDistrict                   Address  \\\n",
       "0   0 2015-05-10 23:59:00    Sunday    BAYVIEW   2000 Block of THOMAS AV   \n",
       "1   1 2015-05-10 23:51:00    Sunday    BAYVIEW        3RD ST / REVERE AV   \n",
       "2   2 2015-05-10 23:50:00    Sunday   NORTHERN    2000 Block of GOUGH ST   \n",
       "3   3 2015-05-10 23:45:00    Sunday  INGLESIDE  4700 Block of MISSION ST   \n",
       "4   4 2015-05-10 23:45:00    Sunday  INGLESIDE  4700 Block of MISSION ST   \n",
       "\n",
       "            X          Y  \n",
       "0 -122.399588  37.735051  \n",
       "1 -122.391523  37.732432  \n",
       "2 -122.426002  37.792212  \n",
       "3 -122.437394  37.721412  \n",
       "4 -122.437394  37.721412  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestD = get_dataframe(\"test.csv\")\n",
    "TestD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = TestD.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Category</th>\n",
       "      <th>Descript</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>WARRANTS</td>\n",
       "      <td>WARRANT ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-13 23:33:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>VANNESS AV / GREENWICH ST</td>\n",
       "      <td>-122.424363</td>\n",
       "      <td>37.800414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>GRAND THEFT FROM LOCKED AUTO</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1500 Block of LOMBARD ST</td>\n",
       "      <td>-122.426995</td>\n",
       "      <td>37.800873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>GRAND THEFT FROM LOCKED AUTO</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>PARK</td>\n",
       "      <td>NONE</td>\n",
       "      <td>100 Block of BRODERICK ST</td>\n",
       "      <td>-122.438738</td>\n",
       "      <td>37.771541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Dates        Category                      Descript  \\\n",
       "0 2015-05-13 23:53:00        WARRANTS                WARRANT ARREST   \n",
       "1 2015-05-13 23:53:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n",
       "2 2015-05-13 23:33:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n",
       "3 2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO   \n",
       "4 2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO   \n",
       "\n",
       "   DayOfWeek PdDistrict      Resolution                    Address  \\\n",
       "0  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n",
       "1  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n",
       "2  Wednesday   NORTHERN  ARREST, BOOKED  VANNESS AV / GREENWICH ST   \n",
       "3  Wednesday   NORTHERN            NONE   1500 Block of LOMBARD ST   \n",
       "4  Wednesday       PARK            NONE  100 Block of BRODERICK ST   \n",
       "\n",
       "            X          Y  \n",
       "0 -122.425892  37.774599  \n",
       "1 -122.425892  37.774599  \n",
       "2 -122.424363  37.800414  \n",
       "3 -122.426995  37.800873  \n",
       "4 -122.438738  37.771541  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainD = get_dataframe(\"train.csv\")\n",
    "TrainD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = TrainD.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "['ARSON', 'ASSAULT', 'BAD CHECKS', 'BRIBERY', 'BURGLARY', 'DISORDERLY CONDUCT', 'DRIVING UNDER THE INFLUENCE', 'DRUG/NARCOTIC', 'DRUNKENNESS', 'EMBEZZLEMENT', 'EXTORTION', 'FAMILY OFFENSES', 'FORGERY/COUNTERFEITING', 'FRAUD', 'GAMBLING', 'KIDNAPPING', 'LARCENY/THEFT', 'LIQUOR LAWS', 'LOITERING', 'MISSING PERSON', 'NON-CRIMINAL', 'OTHER OFFENSES', 'PORNOGRAPHY/OBSCENE MAT', 'PROSTITUTION', 'RECOVERED VEHICLE', 'ROBBERY', 'RUNAWAY', 'SECONDARY CODES', 'SEX OFFENSES FORCIBLE', 'SEX OFFENSES NON FORCIBLE', 'STOLEN PROPERTY', 'SUICIDE', 'SUSPICIOUS OCC', 'TREA', 'TRESPASS', 'VANDALISM', 'VEHICLE THEFT', 'WARRANTS', 'WEAPON LAWS']\n"
     ]
    }
   ],
   "source": [
    "number_of_categories = train_data['Category'].nunique()\n",
    "category_names = sorted(train_data['Category'].unique())\n",
    "print number_of_categories\n",
    "print category_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#labels = train_data[\"Category\"].astype('category')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAKE REGIONS FROM lat/long "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original max and min values\n",
      "---------------------------\n",
      "(-122.51364206429, -120.5, 37.707879022413501, 90.0)\n",
      "New max and min values\n",
      "---------------------------\n",
      "(-122.51364206429, -122.3, 37.707879022413501, 37.799999999999997)\n"
     ]
    }
   ],
   "source": [
    "# Train data:\n",
    "\n",
    "min_x, max_x = np.min(train_data['X']), np.max(train_data['X'])\n",
    "min_y, max_y = np.min(train_data['Y']), np.max(train_data['Y'])\n",
    "print \"Original max and min values\"\n",
    "print \"---------------------------\"\n",
    "print (min_x, max_x,min_y, max_y)\n",
    "\n",
    "\n",
    "# fix invalid values:\n",
    "train_data.loc[train_data['X'] > -122.3, 'X'] = -122.3\n",
    "train_data.loc[train_data['Y'] > 37.8, 'Y'] = 37.8\n",
    "\n",
    "grid_size = 10\n",
    "grid_width = np.max(train_data['X']) - np.min(train_data['X'])\n",
    "grid_height = np.max(train_data['Y']) - np.min(train_data['Y'])\n",
    "\n",
    "x_interval = grid_width/grid_size\n",
    "y_interval = grid_height/grid_size\n",
    "\n",
    "min_x, max_x = np.min(train_data['X']), np.max(train_data['X'])\n",
    "min_y, max_y = np.min(train_data['Y']), np.max(train_data['Y'])\n",
    "\n",
    "train_data['region'] = (10*(np.ceil((train_data['X'] - min_x)/x_interval)) + (np.ceil((train_data['Y'] - min_y)/y_interval))).astype(int)\n",
    "\n",
    "print \"New max and min values\"\n",
    "print \"---------------------------\"\n",
    "print (min_x, max_x, min_y, max_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original max and min values\n",
      "---------------------------\n",
      "(-122.51364206429, -120.5, 37.707879022413501, 90.0)\n",
      "New max and min values\n",
      "---------------------------\n",
      "(-122.51364206429, -122.3, 37.707879022413501, 37.799999999999997)\n"
     ]
    }
   ],
   "source": [
    "# Test data:\n",
    "\n",
    "min_x, max_x = np.min(test_data.loc[:,'X']), np.max(test_data.loc[:,'X'])\n",
    "min_y, max_y = np.min(test_data.loc[:,'Y']), np.max(test_data.loc[:,'Y'])\n",
    "\n",
    "print \"Original max and min values\"\n",
    "print \"---------------------------\"\n",
    "print (min_x, max_x,min_y, max_y)\n",
    "\n",
    "test_data.loc[test_data['X'] > -122.3, 'X'] = -122.3\n",
    "test_data.loc[test_data['Y'] > 37.8, 'Y'] = 37.8\n",
    "\n",
    "grid_size = 10\n",
    "grid_width = np.max(test_data.loc[:,'X']) - np.min(test_data.loc[:,'X'])\n",
    "grid_height = np.max(test_data.loc[:,'Y']) - np.min(test_data.loc[:,'Y'])\n",
    "\n",
    "x_interval = grid_width/grid_size\n",
    "y_interval = grid_height/grid_size\n",
    "\n",
    "min_x, max_x = np.min(test_data.loc[:,'X']), np.max(test_data.loc[:,'X'])\n",
    "min_y, max_y = np.min(test_data.loc[:,'Y']), np.max(test_data.loc[:,'Y'])\n",
    "\n",
    "test_data['region'] = (10*(np.ceil((test_data['X'] - min_x)/x_interval)) + (np.ceil((test_data['Y'] - min_y)/y_interval))).astype(int)\n",
    "\n",
    "print \"New max and min values\"\n",
    "print \"---------------------------\"\n",
    "print (min_x, max_x, min_y, max_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARSE THE DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data.loc[:,'Hour'] = (train_data.loc[:,'Dates']).dt.hour\n",
    "train_data.loc[:,'Month'] = (train_data.loc[:,'Dates']).dt.month\n",
    "train_data.loc[:,'Year'] = (train_data.loc[:,'Dates']).dt.year\n",
    "train_data.loc[:,'Day'] = (train_data.loc[:,'Dates']).dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data['Hour'] = (test_data['Dates']).dt.hour\n",
    "test_data['Month'] = (test_data['Dates']).dt.month\n",
    "test_data['Year'] = (test_data['Dates']).dt.year\n",
    "test_data['Day'] = (test_data['Dates']).dt.day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADDRESSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating logodds address features\n"
     ]
    }
   ],
   "source": [
    "# train data\n",
    "addresses=sorted(train_data[\"Address\"].unique())\n",
    "categories=sorted(train_data[\"Category\"].unique())\n",
    "\n",
    "C_counts=train_data.groupby([\"Category\"]).size()\n",
    "A_C_counts=train_data.groupby([\"Address\",\"Category\"]).size()\n",
    "\n",
    "A_counts=train_data.groupby([\"Address\"]).size()\n",
    "\n",
    "logodds={}\n",
    "logoddsPA={}\n",
    "\n",
    "MIN_CAT_COUNTS=2\n",
    "\n",
    "default_logodds=np.log(C_counts/len(train_data))-np.log(1.0-C_counts/float(len(train_data)))\n",
    "\n",
    "for addr in addresses:\n",
    "    PA=A_counts[addr]/float(len(train_data))\n",
    "    logoddsPA[addr]=np.log(PA)-np.log(1.-PA)\n",
    "    logodds[addr]=deepcopy(default_logodds)\n",
    "    for cat in A_C_counts[addr].keys():\n",
    "        if (A_C_counts[addr][cat]>MIN_CAT_COUNTS) and A_C_counts[addr][cat]<A_counts[addr]:\n",
    "            PA=A_C_counts[addr][cat]/float(A_counts[addr])\n",
    "            logodds[addr][categories.index(cat)]=np.log(PA)-np.log(1.0-PA)\n",
    "    logodds[addr]=pd.Series(logodds[addr])\n",
    "    logodds[addr].index=range(len(categories))\n",
    "    \n",
    "print \"Creating logodds address features\"\n",
    "address_features=train_data[\"Address\"].apply(lambda x: logodds[x])\n",
    "address_features.columns=[\"logodds\"+str(x) for x in range(len(address_features.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data[\"IsInterection\"]=train_data[\"Address\"].apply(lambda x: 1 if \"/\" in x else 0)\n",
    "train_data[\"logoddsPA\"]=train_data[\"Address\"].apply(lambda x: logoddsPA[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.concat([train_data, address_features], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Category</th>\n",
       "      <th>Descript</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>region</th>\n",
       "      <th>...</th>\n",
       "      <th>logodds29</th>\n",
       "      <th>logodds30</th>\n",
       "      <th>logodds31</th>\n",
       "      <th>logodds32</th>\n",
       "      <th>logodds33</th>\n",
       "      <th>logodds34</th>\n",
       "      <th>logodds35</th>\n",
       "      <th>logodds36</th>\n",
       "      <th>logodds37</th>\n",
       "      <th>logodds38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>WARRANTS</td>\n",
       "      <td>WARRANT ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.688077</td>\n",
       "      <td>-5.259591</td>\n",
       "      <td>-7.454398</td>\n",
       "      <td>-3.294016</td>\n",
       "      <td>-11.893691</td>\n",
       "      <td>-4.777894</td>\n",
       "      <td>-2.924890</td>\n",
       "      <td>-2.327278</td>\n",
       "      <td>-2.639057</td>\n",
       "      <td>-4.621396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.688077</td>\n",
       "      <td>-5.259591</td>\n",
       "      <td>-7.454398</td>\n",
       "      <td>-3.294016</td>\n",
       "      <td>-11.893691</td>\n",
       "      <td>-4.777894</td>\n",
       "      <td>-2.924890</td>\n",
       "      <td>-2.327278</td>\n",
       "      <td>-2.639057</td>\n",
       "      <td>-4.621396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-13 23:33:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>VANNESS AV / GREENWICH ST</td>\n",
       "      <td>-122.424363</td>\n",
       "      <td>37.800000</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.688077</td>\n",
       "      <td>-5.259591</td>\n",
       "      <td>-7.454398</td>\n",
       "      <td>-3.294016</td>\n",
       "      <td>-11.893691</td>\n",
       "      <td>-4.777894</td>\n",
       "      <td>-2.924890</td>\n",
       "      <td>-2.729575</td>\n",
       "      <td>-2.985679</td>\n",
       "      <td>-4.621396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>GRAND THEFT FROM LOCKED AUTO</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1500 Block of LOMBARD ST</td>\n",
       "      <td>-122.426995</td>\n",
       "      <td>37.800000</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.688077</td>\n",
       "      <td>-5.259591</td>\n",
       "      <td>-7.454398</td>\n",
       "      <td>-3.630985</td>\n",
       "      <td>-11.893691</td>\n",
       "      <td>-3.925268</td>\n",
       "      <td>-3.212187</td>\n",
       "      <td>-3.401197</td>\n",
       "      <td>-3.925268</td>\n",
       "      <td>-4.621396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>GRAND THEFT FROM LOCKED AUTO</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>PARK</td>\n",
       "      <td>NONE</td>\n",
       "      <td>100 Block of BRODERICK ST</td>\n",
       "      <td>-122.438738</td>\n",
       "      <td>37.771541</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.688077</td>\n",
       "      <td>-5.259591</td>\n",
       "      <td>-7.454398</td>\n",
       "      <td>-2.793208</td>\n",
       "      <td>-11.893691</td>\n",
       "      <td>-4.777894</td>\n",
       "      <td>-2.240710</td>\n",
       "      <td>-2.240710</td>\n",
       "      <td>-2.985679</td>\n",
       "      <td>-4.621396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Dates        Category                      Descript  \\\n",
       "0 2015-05-13 23:53:00        WARRANTS                WARRANT ARREST   \n",
       "1 2015-05-13 23:53:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n",
       "2 2015-05-13 23:33:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n",
       "3 2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO   \n",
       "4 2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO   \n",
       "\n",
       "   DayOfWeek PdDistrict      Resolution                    Address  \\\n",
       "0  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n",
       "1  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n",
       "2  Wednesday   NORTHERN  ARREST, BOOKED  VANNESS AV / GREENWICH ST   \n",
       "3  Wednesday   NORTHERN            NONE   1500 Block of LOMBARD ST   \n",
       "4  Wednesday       PARK            NONE  100 Block of BRODERICK ST   \n",
       "\n",
       "            X          Y  region    ...      logodds29  logodds30  logodds31  \\\n",
       "0 -122.425892  37.774599      58    ...      -8.688077  -5.259591  -7.454398   \n",
       "1 -122.425892  37.774599      58    ...      -8.688077  -5.259591  -7.454398   \n",
       "2 -122.424363  37.800000      60    ...      -8.688077  -5.259591  -7.454398   \n",
       "3 -122.426995  37.800000      60    ...      -8.688077  -5.259591  -7.454398   \n",
       "4 -122.438738  37.771541      47    ...      -8.688077  -5.259591  -7.454398   \n",
       "\n",
       "   logodds32  logodds33  logodds34  logodds35  logodds36  logodds37  logodds38  \n",
       "0  -3.294016 -11.893691  -4.777894  -2.924890  -2.327278  -2.639057  -4.621396  \n",
       "1  -3.294016 -11.893691  -4.777894  -2.924890  -2.327278  -2.639057  -4.621396  \n",
       "2  -3.294016 -11.893691  -4.777894  -2.924890  -2.729575  -2.985679  -4.621396  \n",
       "3  -3.630985 -11.893691  -3.925268  -3.212187  -3.401197  -3.925268  -4.621396  \n",
       "4  -2.793208 -11.893691  -4.777894  -2.240710  -2.240710  -2.985679  -4.621396  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Dates</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>region</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-05-10 23:59:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>2000 Block of THOMAS AV</td>\n",
       "      <td>-122.399588</td>\n",
       "      <td>37.735051</td>\n",
       "      <td>63</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-10 23:51:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>3RD ST / REVERE AV</td>\n",
       "      <td>-122.391523</td>\n",
       "      <td>37.732432</td>\n",
       "      <td>63</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-05-10 23:50:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>2000 Block of GOUGH ST</td>\n",
       "      <td>-122.426002</td>\n",
       "      <td>37.792212</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-05-10 23:45:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>INGLESIDE</td>\n",
       "      <td>4700 Block of MISSION ST</td>\n",
       "      <td>-122.437394</td>\n",
       "      <td>37.721412</td>\n",
       "      <td>42</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-05-10 23:45:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>INGLESIDE</td>\n",
       "      <td>4700 Block of MISSION ST</td>\n",
       "      <td>-122.437394</td>\n",
       "      <td>37.721412</td>\n",
       "      <td>42</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id               Dates DayOfWeek PdDistrict                   Address  \\\n",
       "0   0 2015-05-10 23:59:00    Sunday    BAYVIEW   2000 Block of THOMAS AV   \n",
       "1   1 2015-05-10 23:51:00    Sunday    BAYVIEW        3RD ST / REVERE AV   \n",
       "2   2 2015-05-10 23:50:00    Sunday   NORTHERN    2000 Block of GOUGH ST   \n",
       "3   3 2015-05-10 23:45:00    Sunday  INGLESIDE  4700 Block of MISSION ST   \n",
       "4   4 2015-05-10 23:45:00    Sunday  INGLESIDE  4700 Block of MISSION ST   \n",
       "\n",
       "            X          Y  region  Hour  Month  Year  Day  \n",
       "0 -122.399588  37.735051      63    23      5  2015   10  \n",
       "1 -122.391523  37.732432      63    23      5  2015   10  \n",
       "2 -122.426002  37.792212      60    23      5  2015   10  \n",
       "3 -122.437394  37.721412      42    23      5  2015   10  \n",
       "4 -122.437394  37.721412      42    23      5  2015   10  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test data\n",
    "\n",
    "new_addresses=sorted(test_data[\"Address\"].unique())\n",
    "new_A_counts=test_data.groupby(\"Address\").size()\n",
    "only_new=set(new_addresses+addresses)-set(addresses)\n",
    "only_old=set(new_addresses+addresses)-set(new_addresses)\n",
    "in_both=set(new_addresses).intersection(addresses)\n",
    "in_either=set(new_addresses).union(addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for addr in only_new:\n",
    "    PA=new_A_counts[addr]/float(len(test_data)+len(train_data))\n",
    "    logoddsPA[addr]=np.log(PA)-np.log(1.-PA)\n",
    "    logodds[addr]=deepcopy(default_logodds)\n",
    "    logodds[addr].index=range(len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for addr in in_both:\n",
    "    PA=(A_counts[addr]+new_A_counts[addr])/float(len(test_data)+len(train_data))\n",
    "    logoddsPA[addr]=np.log(PA)-np.log(1.-PA)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating logodds address features\n"
     ]
    }
   ],
   "source": [
    "print \"Creating logodds address features\"\n",
    "test_address_features=test_data[\"Address\"].apply(lambda x: logodds[x])\n",
    "test_address_features.columns=[\"logodds\"+str(x) for x in range(len(test_address_features.columns))]\n",
    "\n",
    "test_data[\"IsInterection\"]=test_data[\"Address\"].apply(lambda x: 1 if \"/\" in x else 0)\n",
    "test_data[\"logoddsPA\"]=test_data[\"Address\"].apply(lambda x: logoddsPA[x])\n",
    "\n",
    "test_data = pd.concat([test_data, test_address_features], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REMOVE UNUSED COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del train_data['Dates']\n",
    "del train_data['Descript']\n",
    "del train_data['X']\n",
    "del train_data['Y']\n",
    "del train_data['Address']\n",
    "del train_data['Resolution']\n",
    "del train_data['Category']\n",
    "\n",
    "del test_data['Dates']\n",
    "del test_data['X']\n",
    "del test_data['Y']\n",
    "del test_data['Address']\n",
    "del test_data['Id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAKE DUMMY VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "days = train_data.loc[:,'DayOfWeek'].unique()\n",
    "le.fit(days)\n",
    "train_data.loc[:,'DayOfWeek'] = le.transform(train_data.loc[:,'DayOfWeek']) \n",
    "\n",
    "\n",
    "days = test_data.loc[:,'DayOfWeek'].unique()\n",
    "le.fit(days)\n",
    "test_data.loc[:,'DayOfWeek'] = le.transform(test_data.loc[:,'DayOfWeek'])\n",
    "\n",
    "\n",
    "district = train_data.loc[:,'PdDistrict'].unique()\n",
    "le.fit(district)\n",
    "train_data.loc[:,'PdDistrict'] = le.transform(train_data.loc[:,'PdDistrict']) \n",
    "\n",
    "\n",
    "district = test_data.loc[:,'PdDistrict'].unique()\n",
    "le.fit(district)\n",
    "test_data.loc[:,'PdDistrict'] = le.transform(test_data.loc[:,'PdDistrict']) \n",
    "\n",
    "\n",
    "district = train_data.loc[:,'region'].unique()\n",
    "le.fit(district)\n",
    "train_data.loc[:,'region'] = le.transform(train_data.loc[:,'region']) \n",
    "\n",
    "\n",
    "district = test_data.loc[:,'region'].unique()\n",
    "le.fit(district)\n",
    "test_data.loc[:,'region'] = le.transform(test_data.loc[:,'region']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# NOT USING THIS - Scale instead.\n",
    "enc = OneHotEncoder()\n",
    "train_data_onehot = enc.fit_transform(train_data) \n",
    "test_data_onehot = enc.fit_transform(test_data)\n",
    "\n",
    "# print train_data_onehot.toarray()\n",
    "print train_data_onehot.shape\n",
    "\n",
    "#print test_data_onehot.toarray()\n",
    "print test_data_onehot.shape\n",
    "\n",
    "#print enc.n_values_\n",
    "#print enc.feature_indices_\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collist=train_data.columns.tolist()\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data[collist]=scaler.transform(train_data)\n",
    "\n",
    "collisttest=test_data.columns.tolist()\n",
    "scalertest = preprocessing.StandardScaler()\n",
    "scalertest.fit(test_data)\n",
    "test_data[collisttest]=scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make train and dev sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(labels, train_size=0.5)\n",
    "\n",
    "for train_index, dev_index in sss:\n",
    "    X_train, X_dev = train_data.iloc[train_index], train_data.iloc[dev_index]\n",
    "    y_train, y_dev = labels[train_index],labels[dev_index]\n",
    "    \n",
    "X_train.index=range(len(X_train))\n",
    "X_dev.index=range(len(X_dev))\n",
    "\n",
    "y_train.index=range(len(y_train))\n",
    "y_dev.index=range(len(y_dev))\n",
    "\n",
    "train_data.index=range(len(train_data))\n",
    "labels.index=range(len(labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier()\n",
    "model = classifier.fit(X_train, y_train)\n",
    "print model.score(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier()\n",
    "model = classifier.fit(X_train, y_train)\n",
    "print model.score(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.202750166276\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "model = classifier.fit(X_train, y_train)\n",
    "print model.score(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = BernoulliNB()\n",
    "model = classifier.fit(X_train, y_train)\n",
    "print model.score(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = MultinomialNB()\n",
    "model = classifier.fit(X_train, y_train)\n",
    "print model.score(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predict and write file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_proba(test_data)\n",
    "withId  = np.column_stack((map(str,xrange(test_data.shape[0])),predictions))\n",
    "towrite = np.row_stack(([\"Id\"] + sorted(y_train.unique()),withId))\n",
    "\n",
    "print(towrite)\n",
    "write_submission('submission_MultiNB.csv', towrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(439024,)\n",
      "(439024, 48)\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train.astype('category')\n",
    "y_train = y_train.cat.rename_categories(range(len(y_train.unique())))\n",
    "\n",
    "print y_train.shape\n",
    "print X_train.shape\n",
    "\n",
    "y_dev = y_dev.astype('category')\n",
    "y_dev = y_dev.cat.rename_categories(range(len(y_dev.unique())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "439024/439024 [==============================] - 26s - loss: 2.5282 - acc: 2.7561e-04    \n",
      "Epoch 2/20\n",
      "408480/439024 [==========================>...] - ETA: 1s - loss: 2.4385 - acc: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "output_dim = 39\n",
    "input_dim = X_train.shape[1]\n",
    "Nlayers = 1\n",
    "Nepoch = 20\n",
    "dp = 0.5\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim=input_dim, output_dim=output_dim, init='glorot_uniform'))\n",
    "model.add(PReLU(input_shape=(input_dim,)))\n",
    "model.add(Dropout(dp))\n",
    "\n",
    "for i in range(Nlayers):\n",
    "    model.add(Dense(input_dim=input_dim, output_dim=output_dim,init='glorot_uniform'))\n",
    "    model.add(PReLU(input_shape=(input_dim,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dp))\n",
    "\n",
    "model.add(Dense(input_dim=input_dim, output_dim=output_dim,init='glorot_uniform'))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "\n",
    "#model.fit(train_data_onehot.toarray(), y_train, nb_epoch=Nepoch, batch_size=32)\n",
    "model.fit(X_train.as_matrix() , y_train, nb_epoch=Nepoch, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
