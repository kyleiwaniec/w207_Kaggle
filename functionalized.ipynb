{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import accelerate\n",
    "#import numbapro\n",
    "import mkl\n",
    "#import iopro\n",
    "\n",
    "# General libraries.\n",
    "from __future__ import division\n",
    "from collections import Counter\n",
    "import csv\n",
    "import dateutil\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SK-learn libraries for preprocessing.\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder # for integer values\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.mixture import GMM\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "from copy import deepcopy\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = \"data\"\n",
    "submissions_path = \"submissions\"\n",
    "if not data_path or not submissions_path:\n",
    "    raise Exception(\"Set the data and submission paths in competition_utilities.py!\")\n",
    "\n",
    "def parse_date_maybe_null(date):\n",
    "    if date:\n",
    "        return dateutil.parser.parse(date)\n",
    "    return None\n",
    "\n",
    "df_converters = {\"Dates\": dateutil.parser.parse}\n",
    "\n",
    "def get_reader(file_name=\"train.csv\"):\n",
    "    reader = csv.reader(open(os.path.join(data_path, file_name)))\n",
    "    header = reader.next()\n",
    "    return reader\n",
    "\n",
    "def get_header(file_name=\"train.csv\"):\n",
    "    reader = csv.reader(open(os.path.join(data_path, file_name)))\n",
    "    header = reader.next()\n",
    "    return header\n",
    "\n",
    "def get_dataframe(file_name=\"train.csv\"):\n",
    "    return pd.io.parsers.read_csv(os.path.join(data_path, file_name), converters = df_converters)\n",
    "\n",
    "    \n",
    "def write_submission(file_name, predictions):\n",
    "    writer = csv.writer(open(os.path.join(submissions_path, file_name), \"w\"), lineterminator=\"\\n\")\n",
    "    writer.writerows(predictions)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Dates</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-05-10 23:59:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>2000 Block of THOMAS AV</td>\n",
       "      <td>-122.399588</td>\n",
       "      <td>37.735051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-10 23:51:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>3RD ST / REVERE AV</td>\n",
       "      <td>-122.391523</td>\n",
       "      <td>37.732432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-05-10 23:50:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>2000 Block of GOUGH ST</td>\n",
       "      <td>-122.426002</td>\n",
       "      <td>37.792212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-05-10 23:45:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>INGLESIDE</td>\n",
       "      <td>4700 Block of MISSION ST</td>\n",
       "      <td>-122.437394</td>\n",
       "      <td>37.721412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-05-10 23:45:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>INGLESIDE</td>\n",
       "      <td>4700 Block of MISSION ST</td>\n",
       "      <td>-122.437394</td>\n",
       "      <td>37.721412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id               Dates DayOfWeek PdDistrict                   Address  \\\n",
       "0   0 2015-05-10 23:59:00    Sunday    BAYVIEW   2000 Block of THOMAS AV   \n",
       "1   1 2015-05-10 23:51:00    Sunday    BAYVIEW        3RD ST / REVERE AV   \n",
       "2   2 2015-05-10 23:50:00    Sunday   NORTHERN    2000 Block of GOUGH ST   \n",
       "3   3 2015-05-10 23:45:00    Sunday  INGLESIDE  4700 Block of MISSION ST   \n",
       "4   4 2015-05-10 23:45:00    Sunday  INGLESIDE  4700 Block of MISSION ST   \n",
       "\n",
       "            X          Y  \n",
       "0 -122.399588  37.735051  \n",
       "1 -122.391523  37.732432  \n",
       "2 -122.426002  37.792212  \n",
       "3 -122.437394  37.721412  \n",
       "4 -122.437394  37.721412  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestD = get_dataframe(\"test.csv\")\n",
    "TestD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make a copy so that you don't have to load the original data if you need to start over\n",
    "test_data = TestD.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Category</th>\n",
       "      <th>Descript</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>WARRANTS</td>\n",
       "      <td>WARRANT ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-13 23:33:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>VANNESS AV / GREENWICH ST</td>\n",
       "      <td>-122.424363</td>\n",
       "      <td>37.800414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>GRAND THEFT FROM LOCKED AUTO</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1500 Block of LOMBARD ST</td>\n",
       "      <td>-122.426995</td>\n",
       "      <td>37.800873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>GRAND THEFT FROM LOCKED AUTO</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>PARK</td>\n",
       "      <td>NONE</td>\n",
       "      <td>100 Block of BRODERICK ST</td>\n",
       "      <td>-122.438738</td>\n",
       "      <td>37.771541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Dates        Category                      Descript  \\\n",
       "0 2015-05-13 23:53:00        WARRANTS                WARRANT ARREST   \n",
       "1 2015-05-13 23:53:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n",
       "2 2015-05-13 23:33:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n",
       "3 2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO   \n",
       "4 2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO   \n",
       "\n",
       "   DayOfWeek PdDistrict      Resolution                    Address  \\\n",
       "0  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n",
       "1  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n",
       "2  Wednesday   NORTHERN  ARREST, BOOKED  VANNESS AV / GREENWICH ST   \n",
       "3  Wednesday   NORTHERN            NONE   1500 Block of LOMBARD ST   \n",
       "4  Wednesday       PARK            NONE  100 Block of BRODERICK ST   \n",
       "\n",
       "            X          Y  \n",
       "0 -122.425892  37.774599  \n",
       "1 -122.425892  37.774599  \n",
       "2 -122.424363  37.800414  \n",
       "3 -122.426995  37.800873  \n",
       "4 -122.438738  37.771541  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainD = get_dataframe(\"train.csv\")\n",
    "TrainD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a copy so that you don't have to load the original data if you need to start over\n",
    "train_data = TrainD.copy(deep=True)\n",
    "train_data=train_data[abs(train_data[\"Y\"])<100]\n",
    "train_data.index=range(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "['ARSON', 'ASSAULT', 'BAD CHECKS', 'BRIBERY', 'BURGLARY', 'DISORDERLY CONDUCT', 'DRIVING UNDER THE INFLUENCE', 'DRUG/NARCOTIC', 'DRUNKENNESS', 'EMBEZZLEMENT', 'EXTORTION', 'FAMILY OFFENSES', 'FORGERY/COUNTERFEITING', 'FRAUD', 'GAMBLING', 'KIDNAPPING', 'LARCENY/THEFT', 'LIQUOR LAWS', 'LOITERING', 'MISSING PERSON', 'NON-CRIMINAL', 'OTHER OFFENSES', 'PORNOGRAPHY/OBSCENE MAT', 'PROSTITUTION', 'RECOVERED VEHICLE', 'ROBBERY', 'RUNAWAY', 'SECONDARY CODES', 'SEX OFFENSES FORCIBLE', 'SEX OFFENSES NON FORCIBLE', 'STOLEN PROPERTY', 'SUICIDE', 'SUSPICIOUS OCC', 'TREA', 'TRESPASS', 'VANDALISM', 'VEHICLE THEFT', 'WARRANTS', 'WEAPON LAWS']\n"
     ]
    }
   ],
   "source": [
    "number_of_categories = train_data['Category'].nunique()\n",
    "category_names = sorted(train_data['Category'].unique())\n",
    "labels = train_data[\"Category\"].astype('category')\n",
    "\n",
    "print number_of_categories\n",
    "print category_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_features(df):\n",
    "    \n",
    "    \n",
    "    ###############################################################\n",
    "    # Make regions from lat/long values\n",
    "    ###############################################################\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    # fix invalid values:\n",
    "    df.loc[df['X'] > -122.3, 'X'] = -122.3\n",
    "    df.loc[df['Y'] > 37.8, 'Y'] = 37.8\n",
    "    \n",
    "    \n",
    "    print \"Creating regions...\"\n",
    "    \n",
    "    grid_size = 20\n",
    "    grid_width = np.max(df['X']) - np.min(df['X'])\n",
    "    grid_height = np.max(df['Y']) - np.min(df['Y'])\n",
    "\n",
    "    x_interval = grid_width/grid_size\n",
    "    y_interval = grid_height/grid_size\n",
    "\n",
    "    min_x, max_x = np.min(df['X']), np.max(df['X'])\n",
    "    min_y, max_y = np.min(df['Y']), np.max(df['Y'])\n",
    "\n",
    "    df['region'] = (10*(np.ceil((df['X'] - min_x)/x_interval)) + (np.ceil((df['Y'] - min_y)/y_interval))).astype(int)\n",
    "\n",
    "    print \"New max and min values\"\n",
    "    print \"---------------------------\"\n",
    "    print (min_x, max_x, min_y, max_y)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ###############################################################\n",
    "    # PARSE THE DATE\n",
    "    ###############################################################\n",
    "    print \"Parsing Dates...\"\n",
    "    \n",
    "    df.loc[:,'Hour'] = (df.loc[:,'Dates']).dt.hour\n",
    "    df.loc[:,'Month'] = (df.loc[:,'Dates']).dt.month\n",
    "    df.loc[:,'Year'] = (df.loc[:,'Dates']).dt.year\n",
    "    df.loc[:,'Day'] = (df.loc[:,'Dates']).dt.day\n",
    "    \n",
    "    ###############################################################\n",
    "    # MAKE SEASONS\n",
    "    ###############################################################\n",
    "    print 'Making seasons...'\n",
    "    def get_season(x):\n",
    "        summer=0\n",
    "        fall=0\n",
    "        winter=0\n",
    "        spring=0\n",
    "        if (x in [5, 6, 7]):\n",
    "            summer=1\n",
    "        if (x in [8, 9, 10]):\n",
    "            fall=1\n",
    "        if (x in [11, 0, 1]):\n",
    "            winter=1\n",
    "        if (x in [2, 3, 4]):\n",
    "            spring=1\n",
    "        return summer, fall, winter, spring\n",
    "    \n",
    "    \n",
    "    df[\"Awake\"] = df[\"Hour\"].apply(lambda x: 1 if (x==0 or (x>=8 and x<=23)) else 0)\n",
    "    df[\"Summer\"], df[\"Fall\"], df[\"Winter\"], df[\"Spring\"] = zip(*df[\"Month\"].apply(get_season))\n",
    "    \n",
    "    ###############################################################\n",
    "    # MARK Duplicates\n",
    "    ###############################################################\n",
    "    print 'Marking dupes...'\n",
    "    df[\"IsDup\"] = pd.Series(df.duplicated()|df.duplicated(take_last=True)).apply(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing Dates...\n",
      "Making seasons...\n",
      "Marking dupes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koza/ipykernel/ipykernel/__main__.py:72: FutureWarning: the take_last=True keyword is deprecated, use keep='last' instead\n"
     ]
    }
   ],
   "source": [
    "train_data = make_features(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing Dates...\n",
      "Making seasons...\n",
      "Marking dupes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koza/ipykernel/ipykernel/__main__.py:72: FutureWarning: the take_last=True keyword is deprecated, use keep='last' instead\n"
     ]
    }
   ],
   "source": [
    "test_data = make_features(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADDRESSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating logodds address features...\n"
     ]
    }
   ],
   "source": [
    "# MAKE ADDRESS FEATURES ON TRAINING DATA:\n",
    "\n",
    "addresses=sorted(train_data[\"Address\"].unique())\n",
    "categories=sorted(train_data[\"Category\"].unique())\n",
    "\n",
    "C_counts=train_data.groupby([\"Category\"]).size()\n",
    "A_C_counts=train_data.groupby([\"Address\",\"Category\"]).size()\n",
    "\n",
    "A_counts=train_data.groupby([\"Address\"]).size()\n",
    "\n",
    "logodds={}\n",
    "logoddsPA={}\n",
    "\n",
    "MIN_CAT_COUNTS=2\n",
    "\n",
    "default_logodds=np.log(C_counts/len(train_data))-np.log(1.0-C_counts/float(len(train_data)))\n",
    "\n",
    "for addr in addresses:\n",
    "    PA=A_counts[addr]/float(len(train_data))\n",
    "    logoddsPA[addr]=np.log(PA)-np.log(1.-PA)\n",
    "    logodds[addr]=deepcopy(default_logodds)\n",
    "    for cat in A_C_counts[addr].keys():\n",
    "        if (A_C_counts[addr][cat]>MIN_CAT_COUNTS) and A_C_counts[addr][cat]<A_counts[addr]:\n",
    "            PA=A_C_counts[addr][cat]/float(A_counts[addr])\n",
    "            logodds[addr][categories.index(cat)]=np.log(PA)-np.log(1.0-PA)\n",
    "    logodds[addr]=pd.Series(logodds[addr])\n",
    "    logodds[addr].index=range(len(categories))\n",
    "    \n",
    "print \"Creating logodds address features...\"\n",
    "address_features=train_data[\"Address\"].apply(lambda x: logodds[x])\n",
    "address_features.columns=[\"logodds\"+str(x) for x in range(len(address_features.columns))]\n",
    "\n",
    "train_data[\"IsInterection\"]=train_data[\"Address\"].apply(lambda x: 1 if \"/\" in x else 0)\n",
    "train_data[\"logoddsPA\"]=train_data[\"Address\"].apply(lambda x: logoddsPA[x])\n",
    "\n",
    "train_data = pd.concat([train_data, address_features], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Dates', u'Category', u'Descript', u'DayOfWeek', u'PdDistrict',\n",
       "       u'Resolution', u'Address', u'X', u'Y', u'IsInterection', u'logoddsPA',\n",
       "       u'logodds0', u'logodds1', u'logodds2', u'logodds3', u'logodds4',\n",
       "       u'logodds5', u'logodds6', u'logodds7', u'logodds8', u'logodds9',\n",
       "       u'logodds10', u'logodds11', u'logodds12', u'logodds13', u'logodds14',\n",
       "       u'logodds15', u'logodds16', u'logodds17', u'logodds18', u'logodds19',\n",
       "       u'logodds20', u'logodds21', u'logodds22', u'logodds23', u'logodds24',\n",
       "       u'logodds25', u'logodds26', u'logodds27', u'logodds28', u'logodds29',\n",
       "       u'logodds30', u'logodds31', u'logodds32', u'logodds33', u'logodds34',\n",
       "       u'logodds35', u'logodds36', u'logodds37', u'logodds38'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating logodds address features\n"
     ]
    }
   ],
   "source": [
    "# MAKE ADDRESS FEATURES ON TEST DATA:\n",
    "\n",
    "new_addresses=sorted(test_data[\"Address\"].unique())\n",
    "new_A_counts=test_data.groupby(\"Address\").size()\n",
    "only_new=set(new_addresses+addresses)-set(addresses)\n",
    "only_old=set(new_addresses+addresses)-set(new_addresses)\n",
    "in_both=set(new_addresses).intersection(addresses)\n",
    "in_either=set(new_addresses).union(addresses)\n",
    "\n",
    "for addr in only_new:\n",
    "    PA=new_A_counts[addr]/float(len(test_data)+len(train_data))\n",
    "    logoddsPA[addr]=np.log(PA)-np.log(1.-PA)\n",
    "    logodds[addr]=deepcopy(default_logodds)\n",
    "    logodds[addr].index=range(len(categories))\n",
    "    \n",
    "for addr in in_both:\n",
    "    PA=(A_counts[addr]+new_A_counts[addr])/float(len(test_data)+len(train_data))\n",
    "    logoddsPA[addr]=np.log(PA)-np.log(1.-PA)   \n",
    "    \n",
    "print \"Creating logodds address features\"\n",
    "test_address_features=test_data[\"Address\"].apply(lambda x: logodds[x])\n",
    "test_address_features.columns=[\"logodds\"+str(x) for x in range(len(test_address_features.columns))]\n",
    "\n",
    "test_data[\"IsInterection\"]=test_data[\"Address\"].apply(lambda x: 1 if \"/\" in x else 0)\n",
    "test_data[\"logoddsPA\"]=test_data[\"Address\"].apply(lambda x: logoddsPA[x])\n",
    "\n",
    "test_data = pd.concat([test_data, test_address_features], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Dates</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-05-10 23:59:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>2000 Block of THOMAS AV</td>\n",
       "      <td>-122.399588</td>\n",
       "      <td>37.735051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-10 23:51:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>3RD ST / REVERE AV</td>\n",
       "      <td>-122.391523</td>\n",
       "      <td>37.732432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-05-10 23:50:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>2000 Block of GOUGH ST</td>\n",
       "      <td>-122.426002</td>\n",
       "      <td>37.792212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-05-10 23:45:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>INGLESIDE</td>\n",
       "      <td>4700 Block of MISSION ST</td>\n",
       "      <td>-122.437394</td>\n",
       "      <td>37.721412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-05-10 23:45:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>INGLESIDE</td>\n",
       "      <td>4700 Block of MISSION ST</td>\n",
       "      <td>-122.437394</td>\n",
       "      <td>37.721412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id               Dates DayOfWeek PdDistrict                   Address  \\\n",
       "0   0 2015-05-10 23:59:00    Sunday    BAYVIEW   2000 Block of THOMAS AV   \n",
       "1   1 2015-05-10 23:51:00    Sunday    BAYVIEW        3RD ST / REVERE AV   \n",
       "2   2 2015-05-10 23:50:00    Sunday   NORTHERN    2000 Block of GOUGH ST   \n",
       "3   3 2015-05-10 23:45:00    Sunday  INGLESIDE  4700 Block of MISSION ST   \n",
       "4   4 2015-05-10 23:45:00    Sunday  INGLESIDE  4700 Block of MISSION ST   \n",
       "\n",
       "            X          Y  \n",
       "0 -122.399588  37.735051  \n",
       "1 -122.391523  37.732432  \n",
       "2 -122.426002  37.792212  \n",
       "3 -122.437394  37.721412  \n",
       "4 -122.437394  37.721412  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAKE DUMMY VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "days = train_data.loc[:,'DayOfWeek'].unique()\n",
    "le.fit(days)\n",
    "train_data.loc[:,'DayOfWeek'] = le.transform(train_data.loc[:,'DayOfWeek']) \n",
    "\n",
    "\n",
    "days = test_data.loc[:,'DayOfWeek'].unique()\n",
    "le.fit(days)\n",
    "test_data.loc[:,'DayOfWeek'] = le.transform(test_data.loc[:,'DayOfWeek'])\n",
    "\n",
    "\n",
    "district = train_data.loc[:,'PdDistrict'].unique()\n",
    "le.fit(district)\n",
    "train_data.loc[:,'PdDistrict'] = le.transform(train_data.loc[:,'PdDistrict']) \n",
    "\n",
    "\n",
    "district = test_data.loc[:,'PdDistrict'].unique()\n",
    "le.fit(district)\n",
    "test_data.loc[:,'PdDistrict'] = le.transform(test_data.loc[:,'PdDistrict']) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Dates</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>region</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Month</th>\n",
       "      <th>...</th>\n",
       "      <th>logodds29</th>\n",
       "      <th>logodds30</th>\n",
       "      <th>logodds31</th>\n",
       "      <th>logodds32</th>\n",
       "      <th>logodds33</th>\n",
       "      <th>logodds34</th>\n",
       "      <th>logodds35</th>\n",
       "      <th>logodds36</th>\n",
       "      <th>logodds37</th>\n",
       "      <th>logodds38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-05-10 23:59:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2000 Block of THOMAS AV</td>\n",
       "      <td>-122.399588</td>\n",
       "      <td>37.735051</td>\n",
       "      <td>116</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.688077</td>\n",
       "      <td>-5.259591</td>\n",
       "      <td>-7.454398</td>\n",
       "      <td>-2.772589</td>\n",
       "      <td>-11.893691</td>\n",
       "      <td>-4.777894</td>\n",
       "      <td>-2.533697</td>\n",
       "      <td>-2.335375</td>\n",
       "      <td>-2.533697</td>\n",
       "      <td>-4.621396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-10 23:51:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3RD ST / REVERE AV</td>\n",
       "      <td>-122.391523</td>\n",
       "      <td>37.732432</td>\n",
       "      <td>126</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.688077</td>\n",
       "      <td>-5.259591</td>\n",
       "      <td>-7.454398</td>\n",
       "      <td>-3.332205</td>\n",
       "      <td>-11.893691</td>\n",
       "      <td>-4.777894</td>\n",
       "      <td>-2.924890</td>\n",
       "      <td>-2.682075</td>\n",
       "      <td>-2.159484</td>\n",
       "      <td>-4.199705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-05-10 23:50:00</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2000 Block of GOUGH ST</td>\n",
       "      <td>-122.426002</td>\n",
       "      <td>37.792212</td>\n",
       "      <td>109</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.688077</td>\n",
       "      <td>-5.259591</td>\n",
       "      <td>-7.454398</td>\n",
       "      <td>-3.294016</td>\n",
       "      <td>-11.893691</td>\n",
       "      <td>-4.777894</td>\n",
       "      <td>-2.924890</td>\n",
       "      <td>-1.223775</td>\n",
       "      <td>-2.985679</td>\n",
       "      <td>-4.621396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-05-10 23:45:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4700 Block of MISSION ST</td>\n",
       "      <td>-122.437394</td>\n",
       "      <td>37.721412</td>\n",
       "      <td>83</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.688077</td>\n",
       "      <td>-5.259591</td>\n",
       "      <td>-7.454398</td>\n",
       "      <td>-2.888233</td>\n",
       "      <td>-11.893691</td>\n",
       "      <td>-5.095793</td>\n",
       "      <td>-2.373798</td>\n",
       "      <td>-4.240298</td>\n",
       "      <td>-2.929592</td>\n",
       "      <td>-3.608837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-05-10 23:45:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4700 Block of MISSION ST</td>\n",
       "      <td>-122.437394</td>\n",
       "      <td>37.721412</td>\n",
       "      <td>83</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.688077</td>\n",
       "      <td>-5.259591</td>\n",
       "      <td>-7.454398</td>\n",
       "      <td>-2.888233</td>\n",
       "      <td>-11.893691</td>\n",
       "      <td>-5.095793</td>\n",
       "      <td>-2.373798</td>\n",
       "      <td>-4.240298</td>\n",
       "      <td>-2.929592</td>\n",
       "      <td>-3.608837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id               Dates  DayOfWeek  PdDistrict                   Address  \\\n",
       "0   0 2015-05-10 23:59:00          3           0   2000 Block of THOMAS AV   \n",
       "1   1 2015-05-10 23:51:00          3           0        3RD ST / REVERE AV   \n",
       "2   2 2015-05-10 23:50:00          3           4    2000 Block of GOUGH ST   \n",
       "3   3 2015-05-10 23:45:00          3           2  4700 Block of MISSION ST   \n",
       "4   4 2015-05-10 23:45:00          3           2  4700 Block of MISSION ST   \n",
       "\n",
       "            X          Y  region  Hour  Month    ...      logodds29  \\\n",
       "0 -122.399588  37.735051     116    23      5    ...      -8.688077   \n",
       "1 -122.391523  37.732432     126    23      5    ...      -8.688077   \n",
       "2 -122.426002  37.792212     109    23      5    ...      -8.688077   \n",
       "3 -122.437394  37.721412      83    23      5    ...      -8.688077   \n",
       "4 -122.437394  37.721412      83    23      5    ...      -8.688077   \n",
       "\n",
       "   logodds30  logodds31  logodds32  logodds33  logodds34  logodds35  \\\n",
       "0  -5.259591  -7.454398  -2.772589 -11.893691  -4.777894  -2.533697   \n",
       "1  -5.259591  -7.454398  -3.332205 -11.893691  -4.777894  -2.924890   \n",
       "2  -5.259591  -7.454398  -3.294016 -11.893691  -4.777894  -2.924890   \n",
       "3  -5.259591  -7.454398  -2.888233 -11.893691  -5.095793  -2.373798   \n",
       "4  -5.259591  -7.454398  -2.888233 -11.893691  -5.095793  -2.373798   \n",
       "\n",
       "   logodds36  logodds37  logodds38  \n",
       "0  -2.335375  -2.533697  -4.621396  \n",
       "1  -2.682075  -2.159484  -4.199705  \n",
       "2  -1.223775  -2.985679  -4.621396  \n",
       "3  -4.240298  -2.929592  -3.608837  \n",
       "4  -4.240298  -2.929592  -3.608837  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make one-hot from columns\n",
    "def make_one_hot(df, columns=['PdDistrict','region']):\n",
    "    enc = OneHotEncoder()\n",
    "    \n",
    "    df_onehot = df[columns]\n",
    "    df_onehot = enc.fit_transform(df_onehot) \n",
    "\n",
    "    #print enc.n_values_\n",
    "    #print enc.feature_indices_\n",
    "    \n",
    "    return df_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "districts_test = make_one_hot(test_data, columns=['PdDistrict'])\n",
    "districts_test_df = pd.DataFrame(data=districts_test.toarray()) \n",
    "districts_test_df.columns = ['PdDistrict_'+ str(col) for col in districts_test_df.columns]\n",
    "\n",
    "DayOfWeek_test = make_one_hot(test_data, columns=['DayOfWeek'])\n",
    "DayOfWeek_test_df = pd.DataFrame(data=DayOfWeek_test.toarray()) \n",
    "DayOfWeek_test_df.columns = ['DayOfWeek_'+ str(col) for col in DayOfWeek_test_df.columns]\n",
    "\n",
    "test_data = pd.concat([test_data, districts_test_df, DayOfWeek_test_df], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "districts_train = make_one_hot(train_data, columns=['PdDistrict'])\n",
    "districts_train_df = pd.DataFrame(data=districts_train.toarray()) \n",
    "districts_train_df.columns = ['PdDistrict_'+ str(col) for col in districts_train_df.columns]\n",
    "\n",
    "DayOfWeek_train = make_one_hot(train_data, columns=['DayOfWeek'])\n",
    "DayOfWeek_train_df = pd.DataFrame(data=DayOfWeek_train.toarray()) \n",
    "DayOfWeek_train_df.columns = ['DayOfWeek_'+ str(col) for col in DayOfWeek_train_df.columns]\n",
    "\n",
    "train_data = pd.concat([train_data, districts_train_df, DayOfWeek_train_df], axis=1, join='inner')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REMOVE UNUSED COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_unused_cols(df, data_src='train'):\n",
    "    del df['Dates']\n",
    "#     del df['X']\n",
    "#     del df['Y']\n",
    "    del df['Address']\n",
    "    del df['DayOfWeek']\n",
    "    del df['PdDistrict']\n",
    "        \n",
    "    if data_src == 'train':\n",
    "        del df['Descript']\n",
    "        del df['Resolution']\n",
    "        del df['Category']\n",
    "    else:\n",
    "        del df['Id']\n",
    "        \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = remove_unused_cols(train_data,'train')\n",
    "test_data = remove_unused_cols(test_data,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'Y', 'region', 'Hour', 'Month', 'Year', 'Day', 'Awake', 'Summer', 'Fall', 'Winter', 'Spring', 'IsDup', 'IsInterection', 'logoddsPA', 'logodds0', 'logodds1', 'logodds2', 'logodds3', 'logodds4', 'logodds5', 'logodds6', 'logodds7', 'logodds8', 'logodds9', 'logodds10', 'logodds11', 'logodds12', 'logodds13', 'logodds14', 'logodds15', 'logodds16', 'logodds17', 'logodds18', 'logodds19', 'logodds20', 'logodds21', 'logodds22', 'logodds23', 'logodds24', 'logodds25', 'logodds26', 'logodds27', 'logodds28', 'logodds29', 'logodds30', 'logodds31', 'logodds32', 'logodds33', 'logodds34', 'logodds35', 'logodds36', 'logodds37', 'logodds38', 'PdDistrict_0', 'PdDistrict_1', 'PdDistrict_2', 'PdDistrict_3', 'PdDistrict_4', 'PdDistrict_5', 'PdDistrict_6', 'PdDistrict_7', 'PdDistrict_8', 'PdDistrict_9', 'DayOfWeek_0', 'DayOfWeek_1', 'DayOfWeek_2', 'DayOfWeek_3', 'DayOfWeek_4', 'DayOfWeek_5', 'DayOfWeek_6']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>region</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Day</th>\n",
       "      <th>Awake</th>\n",
       "      <th>Summer</th>\n",
       "      <th>Fall</th>\n",
       "      <th>...</th>\n",
       "      <th>PdDistrict_7</th>\n",
       "      <th>PdDistrict_8</th>\n",
       "      <th>PdDistrict_9</th>\n",
       "      <th>DayOfWeek_0</th>\n",
       "      <th>DayOfWeek_1</th>\n",
       "      <th>DayOfWeek_2</th>\n",
       "      <th>DayOfWeek_3</th>\n",
       "      <th>DayOfWeek_4</th>\n",
       "      <th>DayOfWeek_5</th>\n",
       "      <th>DayOfWeek_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "      <td>105</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "      <td>105</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.424363</td>\n",
       "      <td>37.800000</td>\n",
       "      <td>110</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.426995</td>\n",
       "      <td>37.800000</td>\n",
       "      <td>110</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.438738</td>\n",
       "      <td>37.771541</td>\n",
       "      <td>94</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            X          Y  region  Hour  Month  Year  Day  Awake  Summer  Fall  \\\n",
       "0 -122.425892  37.774599     105    23      5  2015   13      1       1     0   \n",
       "1 -122.425892  37.774599     105    23      5  2015   13      1       1     0   \n",
       "2 -122.424363  37.800000     110    23      5  2015   13      1       1     0   \n",
       "3 -122.426995  37.800000     110    23      5  2015   13      1       1     0   \n",
       "4 -122.438738  37.771541      94    23      5  2015   13      1       1     0   \n",
       "\n",
       "      ...       PdDistrict_7  PdDistrict_8  PdDistrict_9  DayOfWeek_0  \\\n",
       "0     ...                0.0           0.0           0.0          0.0   \n",
       "1     ...                0.0           0.0           0.0          0.0   \n",
       "2     ...                0.0           0.0           0.0          0.0   \n",
       "3     ...                0.0           0.0           0.0          0.0   \n",
       "4     ...                0.0           0.0           0.0          0.0   \n",
       "\n",
       "   DayOfWeek_1  DayOfWeek_2  DayOfWeek_3  DayOfWeek_4  DayOfWeek_5  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "3          0.0          0.0          0.0          0.0          0.0   \n",
       "4          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   DayOfWeek_6  \n",
       "0          1.0  \n",
       "1          1.0  \n",
       "2          1.0  \n",
       "3          1.0  \n",
       "4          1.0  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print train_data.columns.tolist()\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make train and dev sets\n",
    "We have very uneven portions of classes. Therefore a stratified sampling makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(labels, train_size=0.5)\n",
    "\n",
    "for train_index, dev_index in sss:\n",
    "    X_train, X_dev = train_data.iloc[train_index], train_data.iloc[dev_index]\n",
    "    y_train, y_dev = labels[train_index],labels[dev_index]\n",
    "    \n",
    "X_train.index=range(len(X_train))\n",
    "X_dev.index=range(len(X_dev))\n",
    "\n",
    "y_train.index=range(len(y_train))\n",
    "y_dev.index=range(len(y_dev))\n",
    "\n",
    "train_data.index=range(len(train_data))\n",
    "labels.index=range(len(labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier()\n",
    "model = classifier.fit(X_train, y_train)\n",
    "print model.score(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier()\n",
    "model = classifier.fit(X_train, y_train)\n",
    "print model.score(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = LogisticRegression()\n",
    "model = classifier.fit(X_train, y_train)\n",
    "print model.score(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = BernoulliNB()\n",
    "model = classifier.fit(X_train, y_train)\n",
    "print model.score(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = MultinomialNB()\n",
    "model = classifier.fit(X_train, y_train)\n",
    "print model.score(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predict and write file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_proba(test_data)\n",
    "withId  = np.column_stack((map(str,xrange(test_data.shape[0])),predictions))\n",
    "towrite = np.row_stack(([\"Id\"] + sorted(y_train.unique()),withId))\n",
    "\n",
    "print(towrite)\n",
    "write_submission('submission_MultiNB.csv', towrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koza/ipykernel/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/koza/anaconda2/lib/python2.7/site-packages/pandas/core/indexing.py:461: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "def scale_data(dfs=[train_data,test_data,X_train,X_dev]):\n",
    "    for d in dfs:\n",
    "        collist=d.columns.tolist()\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "        scaler.fit(d)\n",
    "        d[collist]=scaler.transform(d)\n",
    "    return train_data,test_data,X_train,X_dev\n",
    "\n",
    "train_data,test_data,X_train,X_dev = scale_data(dfs=[train_data,test_data,X_train,X_dev])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.recurrent import LSTM, GRU, SimpleRNN\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-97d6eba30408>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename_categories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "y_train = y_train.astype('category')\n",
    "y_train = y_train.cat.rename_categories(range(len(y_train.unique())))\n",
    "\n",
    "print y_train.shape\n",
    "print X_train.shape\n",
    "\n",
    "y_dev = y_dev.astype('category')\n",
    "y_dev = y_dev.cat.rename_categories(range(len(y_dev.unique())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3333829301ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mN_LAYERS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mDP\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename_categories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "N_EPOCHS=5\n",
    "N_HN=10\n",
    "N_LAYERS=1\n",
    "DP=0.5\n",
    "input_dim=X_train.shape[1]\n",
    "output_dim=len(labels_train.unique())\n",
    "Y_train=y_train.cat.rename_categories(range(len(y_train.unique())))\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim=input_dim, output_dim=N_HN, init='glorot_uniform'))\n",
    "model.add(PReLU(input_shape=(N_HN,)))\n",
    "model.add(Dropout(dp))\n",
    "\n",
    "for i in range(layers):\n",
    "    model.add(Dense(input_dim=N_HN, output_dim=N_HN,init='glorot_uniform'))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.add(PReLU(input_shape=(N_HN,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dp))\n",
    "\n",
    "model.add(Dense(input_dim=N_HN, output_dim=output_dim,init='glorot_uniform'))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')    \n",
    "    \n",
    "\n",
    "model.fit(X_train.as_matrix(), y_train, nb_epoch=Nepoch, batch_size=NBatch,validation_data=(X_dev.as_matrix(),y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.28427365966\n",
      "dev 2.29383120554\n",
      "all 2.30952260183\n"
     ]
    }
   ],
   "source": [
    "print \"train\", log_loss(y_train, model.predict_proba(X_train.as_matrix(),verbose=0))\n",
    "print \"dev\", log_loss(y_dev, model.predict_proba(X_dev.as_matrix(),verbose=0))\n",
    "print \"all\", log_loss(labels, model.predict_proba(train_data.as_matrix(),verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(878049, 71)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "878049/878049 [==============================] - 50s - loss: 2.4384    \n",
      "Epoch 2/20\n",
      "878049/878049 [==============================] - 50s - loss: 2.3616    \n",
      "Epoch 3/20\n",
      "878049/878049 [==============================] - 55s - loss: 2.3535    \n",
      "Epoch 4/20\n",
      "878049/878049 [==============================] - 56s - loss: 2.3491    \n",
      "Epoch 5/20\n",
      "878049/878049 [==============================] - 54s - loss: 2.3456    \n",
      "Epoch 6/20\n",
      "878049/878049 [==============================] - 52s - loss: 2.3428    \n",
      "Epoch 7/20\n",
      "878049/878049 [==============================] - 52s - loss: 2.3413    \n",
      "Epoch 8/20\n",
      "878049/878049 [==============================] - 58s - loss: 2.3409    \n",
      "Epoch 9/20\n",
      "878049/878049 [==============================] - 54s - loss: 2.3393    \n",
      "Epoch 10/20\n",
      "878049/878049 [==============================] - 52s - loss: 2.3385    \n",
      "Epoch 11/20\n",
      "878049/878049 [==============================] - 51s - loss: 2.3380    \n",
      "Epoch 12/20\n",
      "878049/878049 [==============================] - 58s - loss: 2.3380    \n",
      "Epoch 13/20\n",
      "878049/878049 [==============================] - 56s - loss: 2.3370    \n",
      "Epoch 14/20\n",
      "878049/878049 [==============================] - 54s - loss: 2.3365    \n",
      "Epoch 15/20\n",
      "878049/878049 [==============================] - 52s - loss: 2.3356    \n",
      "Epoch 16/20\n",
      "878049/878049 [==============================] - 52s - loss: 2.3357    \n",
      "Epoch 17/20\n",
      "878049/878049 [==============================] - 52s - loss: 2.3353    \n",
      "Epoch 18/20\n",
      "878049/878049 [==============================] - 51s - loss: 2.3350    \n",
      "Epoch 19/20\n",
      "878049/878049 [==============================] - 50s - loss: 2.3345    \n",
      "Epoch 20/20\n",
      "878049/878049 [==============================] - 50s - loss: 2.3351    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15ae16d90>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_data.as_matrix()\n",
    "Y = labels.cat.rename_categories(range(len(labels.unique())))\n",
    "\n",
    "Nlayers = 1\n",
    "Nepoch = 20\n",
    "input_dim = train_data.shape[1]\n",
    "output_dim = 39\n",
    "hn = 128\n",
    "NBatch = 64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim=input_dim, output_dim=hn, init='glorot_uniform'))\n",
    "model.add(PReLU(input_shape=(hn,)))\n",
    "model.add(Dropout(dp))\n",
    "\n",
    "for i in range(Nlayers):\n",
    "    model.add(Dense(input_dim=hn, output_dim=hn,init='glorot_uniform'))\n",
    "    model.add(PReLU(input_shape=(hn,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dp))\n",
    "\n",
    "model.add(Dense(input_dim=hn, output_dim=output_dim,init='glorot_uniform'))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "    \n",
    "model.fit(X, Y, nb_epoch=Nepoch, batch_size=NBatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.313499976\n",
      "dev 2.31556292382\n",
      "all 2.28215142557\n"
     ]
    }
   ],
   "source": [
    "print \"train\", log_loss(y_train, model.predict_proba(X_train.as_matrix(),verbose=0))\n",
    "print \"dev\", log_loss(y_dev, model.predict_proba(X_dev.as_matrix(),verbose=0))\n",
    "print \"all\", log_loss(labels, model.predict_proba(train_data.as_matrix(),verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predDF=pd.DataFrame(model.predict_proba(test_data.as_matrix(),verbose=0),columns=sorted(labels.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predDF.to_csv(os.path.join(submissions_path, \"predictions_x.csv\"),index_label=\"Id\",na_rep=\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
